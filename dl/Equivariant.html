
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />
<meta content="Deep Learning for Molecules &amp; Materials Book" lang="en" name="description" xml:lang="en" />
<meta content="en_US" property="og:locale" />
<meta content="summary" name="twitter:card" />
<meta content="Deep Learning for Molecules &amp; Materials Book" name="twitter:description" />
<meta content="dmol.pub üìñ" name="twitter:title" />
<meta content="https://dmol.pub/_static/logo.png" name="twitter:image" />
<meta content="&#64;andrewwhite01" name="twitter:site" />

    <title>10. Equivariant Neural Networks &#8212; deep learning for molecules &amp; materials</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/a11y.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/custom.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="https://resnant.github.io/dmol-book-japanese/dl/Equivariant.html" />
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="11. Modern Molecular NNs" href="molnets.html" />
    <link rel="prev" title="9. Input Data &amp; Equivariances" href="data.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">deep learning for molecules & materials</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   „Åì„ÅÆÊú¨„ÅÆÊ¶ÇË¶Å
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  A. Math Review
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../math/tensors-and-shapes.html">
   1. Tensors and Shapes
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  B. Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ml/introduction.html">
   2. Ê©üÊ¢∞Â≠¶ÁøíÂÖ•ÈñÄ
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml/regression.html">
   3. Regression &amp; Model Assessment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml/classification.html">
   4. Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml/kernel.html">
   5. „Ç´„Éº„Éç„É´Â≠¶Áøí
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  C. Deep Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="introduction.html">
   6. „Éá„Ç£„Éº„Éó„É©„Éº„Éã„É≥„Ç∞„ÅÆÊ¶ÇË¶Å
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="layers.html">
   7. Standard Layers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="gnn.html">
   8. Graph Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="data.html">
   9. Input Data &amp; Equivariances
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   10. Equivariant Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="molnets.html">
   11. Modern Molecular NNs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="xai.html">
   12. ‰∫àÊ∏¨„ÇíË™¨Êòé„Åô„Çã
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="attention.html">
   13. „Ç¢„ÉÜ„É≥„Ç∑„Éß„É≥„É¨„Ç§„É§„Éº
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NLP.html">
   15. Deep Learning on Sequences
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="VAE.html">
   16. Variational Autoencoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="flows.html">
   17. Normalizing Flows
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  D. Applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../applied/QM9.html">
   18. GNN„Å´„Çà„ÇãDFT„Ç®„Éç„É´„ÇÆ„Éº„ÅÆ‰∫àÊ∏¨
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../applied/MolGenerator.html">
   19. Generative RNN in Browser
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  E. Contributed Chapters
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Hyperparameter_tuning.html">
   20. Hyperparameter Tuning
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  F. Appendix
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../style.html">
   21. Style Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../changelog.html">
   22. Changelog
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  <script async defer src="https://api.dmol.pub/latest.js"></script><noscript><img src="https://api.dmol.pub/noscript.gif" alt="" referrerpolicy="no-referrer-when-downgrade" /></noscript> By <a href="https://twitter.com/andrewwhite01">Andrew White</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/dl/Equivariant.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/resnant/dmol-book-japanese/"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/resnant/dmol-book-japanese//issues/new?title=Issue%20on%20page%20%2Fdl/Equivariant.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/resnant/dmol-book-japanese/blob/master/dl/Equivariant.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#do-you-need-equivariance">
   10.1. Do you need equivariance?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#running-this-notebook">
   10.2. Running This Notebook
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#outline">
     10.2.1. Outline
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#group-theory">
   10.3. Group Theory
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#finite-group-z-6">
     10.3.1. ‚¨° Finite Group
     <span class="math notranslate nohighlight">
      \(Z_6\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#p4m">
     10.3.2. ‚ñ© p4m
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#so-3-group">
     10.3.3. ‚öΩ SO(3) Group
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#groups-on-spaces">
     10.3.4. Groups on Spaces
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#equivariance-definition">
   10.4. Equivariance Definition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#g-equivariant-convolution-layers">
   10.5. G-Equivariant Convolution Layers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#converting-between-space-and-group">
   10.6. Converting between Space and Group
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#g-equivariant-convolutions-on-finite-groups">
   10.7. G-Equivariant Convolutions on Finite Groups
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#g-equivariant-convolutions-with-translation">
   10.8. G-Equivariant Convolutions with Translation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#group-representation">
   10.9. Group Representation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unitary-representations">
     10.9.1. Unitary Representations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#irreducible-representations">
     10.9.2. Irreducible representations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#g-equivariant-convolutions-on-compact-groups">
   10.10. G-Equivariant Convolutions on Compact Groups
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#irreducible-representations-on-so-3">
     10.10.1. Irreducible representations on SO(3)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#so-3-nonlinearity-mixing">
     10.10.2. SO(3) Nonlinearity &amp; Mixing
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#so-3-equivariant-example">
   10.11. SO(3) Equivariant Example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#equivariant-neural-networks-with-constraints">
   10.12. Equivariant Neural Networks with Constraints
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-the-constraints-work">
     10.12.1. How the constraints work
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#including-permutation-groups">
     10.12.2. Including Permutation Groups
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#chapter-summary">
   10.13. Chapter Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#relevant-videos">
   10.14. Relevant Videos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#intro-to-geometric-deep-learning">
     10.14.1. Intro to Geometric Deep Learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#equivariant-networks">
     10.14.2. Equivariant Networks
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#equivariant-network-tutorial">
     10.14.3. Equivariant Network Tutorial
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cited-references">
   10.15. Cited References
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Equivariant Neural Networks</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#do-you-need-equivariance">
   10.1. Do you need equivariance?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#running-this-notebook">
   10.2. Running This Notebook
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#outline">
     10.2.1. Outline
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#group-theory">
   10.3. Group Theory
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#finite-group-z-6">
     10.3.1. ‚¨° Finite Group
     <span class="math notranslate nohighlight">
      \(Z_6\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#p4m">
     10.3.2. ‚ñ© p4m
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#so-3-group">
     10.3.3. ‚öΩ SO(3) Group
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#groups-on-spaces">
     10.3.4. Groups on Spaces
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#equivariance-definition">
   10.4. Equivariance Definition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#g-equivariant-convolution-layers">
   10.5. G-Equivariant Convolution Layers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#converting-between-space-and-group">
   10.6. Converting between Space and Group
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#g-equivariant-convolutions-on-finite-groups">
   10.7. G-Equivariant Convolutions on Finite Groups
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#g-equivariant-convolutions-with-translation">
   10.8. G-Equivariant Convolutions with Translation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#group-representation">
   10.9. Group Representation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unitary-representations">
     10.9.1. Unitary Representations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#irreducible-representations">
     10.9.2. Irreducible representations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#g-equivariant-convolutions-on-compact-groups">
   10.10. G-Equivariant Convolutions on Compact Groups
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#irreducible-representations-on-so-3">
     10.10.1. Irreducible representations on SO(3)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#so-3-nonlinearity-mixing">
     10.10.2. SO(3) Nonlinearity &amp; Mixing
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#so-3-equivariant-example">
   10.11. SO(3) Equivariant Example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#equivariant-neural-networks-with-constraints">
   10.12. Equivariant Neural Networks with Constraints
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-the-constraints-work">
     10.12.1. How the constraints work
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#including-permutation-groups">
     10.12.2. Including Permutation Groups
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#chapter-summary">
   10.13. Chapter Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#relevant-videos">
   10.14. Relevant Videos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#intro-to-geometric-deep-learning">
     10.14.1. Intro to Geometric Deep Learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#equivariant-networks">
     10.14.2. Equivariant Networks
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#equivariant-network-tutorial">
     10.14.3. Equivariant Network Tutorial
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cited-references">
   10.15. Cited References
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="equivariant-neural-networks">
<h1><span class="section-number">10. </span>Equivariant Neural Networks<a class="headerlink" href="#equivariant-neural-networks" title="Permalink to this headline">¬∂</a></h1>
<p>The previous chapter <a class="reference internal" href="data.html"><span class="doc">Input Data &amp; Equivariances</span></a> discussed data transformation and network architecture decisions that can be made to make a neural network equivariant with respect to translation, rotation, and permutations. However, those ideas limit the expressibility of our networks and are constructed ad-hoc. Now we will take a more systematic approach to defining equivariances and prove that there is only one layer type that can preserve a given equivariance. The result of this section will be layers that can be equivariant with respect to any transform, even for more esoteric cases like points on a sphere or mirror operations. To achieve this, we will need tools from group theory, representation theory, harmonic analysis, and deep learning. Equivariant neural networks are part of a broader topic of <strong>geometric deep learning</strong>, which is learning with data that has some underlying geometric relationships. Geometric deep learning is thus a broad-topic and includes the ‚Äú5Gs‚Äù: grids, groups, graphs, geodesics, and gauges. However, you‚Äôll see papers with that nomenclature concentrated on point clouds (gauges), whereas graph learning and grids are usually called graph neural networks and convolutions neural networks respectively.</p>
<div class="admonition-audience-objectives admonition">
<p class="admonition-title">Audience &amp; Objectives</p>
<p>This chapter builds on <a class="reference internal" href="data.html"><span class="doc">Input Data &amp; Equivariances</span></a> and a strong background in math. Although not required, a background on Hilbert spaces, group theory, representation theory, Fourier series, and Lie algebra will help. After completing this chapter, you should be able to</p>
<ul class="simple">
<li><p>Derive and understand the mathematical foundations of equivariant neural networks</p></li>
<li><p>Reason about equivariances of neural networks</p></li>
<li><p>Know common symmetry groups</p></li>
<li><p>Implement G-equivariant neural network layers</p></li>
<li><p>Understand the shape, purpose, and derivation of irreducible function representations</p></li>
<li><p>Know how weight-constraints can be used as an alternative</p></li>
</ul>
</div>
<div class="admonition danger">
<p class="admonition-title">Danger</p>
<p>This chapter teaches how to add equivariance for point clouds, but not permutations. To work with multiple molecules of different size/shape, we need to combine ideas from this chapter with permtuation equivariance from the <a class="reference internal" href="gnn.html"><span class="doc">Graph Neural Networks</span></a> chapter. That combination is explored in <a class="reference internal" href="molnets.html"><span class="doc">Modern Molecular NNs</span></a>. If you‚Äôre always working with atoms/points in the same order, you can ignore permutation equivariance.</p>
</div>
<section id="do-you-need-equivariance">
<h2><span class="section-number">10.1. </span>Do you need equivariance?<a class="headerlink" href="#do-you-need-equivariance" title="Permalink to this headline">¬∂</a></h2>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>I‚Äôm being a bit unfair, these papers have some slightly different application areas (lie vs compact vs finite groups) and differ mostly in their nonlinearity.</p>
</aside>
<p>Before we get too far, let me first try to talk you out of equivariant networks. The math required is advanced, especially because the theory of these is still in flux. There are five papers in the last few years that propose a general theory for equivariant networks and they each take a slightly different approach <span id="id1">[<a class="reference internal" href="#id107" title="Marc Finzi, Samuel Stanton, Pavel Izmailov, and Andrew Gordon Wilson. Generalizing convolutional neural networks for equivariance to lie groups on arbitrary continuous data. arXiv preprint arXiv:2002.12880, 2020.">FSIW20</a>, <a class="reference internal" href="#id105" title="Taco S Cohen, Mario Geiger, and Maurice Weiler. A general theory of equivariant cnns on homogeneous spaces. Advances in neural information processing systems, 32:9145‚Äì9156, 2019.">CGW19</a>, <a class="reference internal" href="#id104" title="Risi Kondor and Shubhendu Trivedi. On the generalization of equivariance and convolution in neural networks to the action of compact groups. In International Conference on Machine Learning, 2747‚Äì2755. 2018.">KT18</a>, <a class="reference internal" href="#id117" title="Leon Lang and Maurice Weiler. A wigner-eckart theorem for group equivariant convolution kernels. arXiv preprint arXiv:2010.10952, 2020.">LW20</a>, <a class="reference internal" href="#id149" title="Marc Finzi, Max Welling, and Andrew Gordon Wilson. A practical method for constructing equivariant multilayer perceptrons for arbitrary matrix groups. Arxiv, 2021.">FWW21</a>]</span>. It is also easy to make mistakes in implementations due to the complexity of the methods. You must also do some of the implementation details yourself, because general efficient implementations of groups is still not solved (although we are <a class="reference external" href="https://developer.nvidia.com/blog/accelerating-se3-transformers-training-using-an-nvidia-open-source-model-implementation/">getting close now for specifically SE(3)</a>). You will also find that equivariant networks are not in general state of the art on point clouds ‚Äì although that is starting to change with recent benchmarks set in point cloud segmentation <span id="id2">[<a class="reference internal" href="#id110" title="Renhao Wang, Marjan Albooyeh, and Siamak Ravanbakhsh. Equivariant maps for hierarchical structures. arXiv preprint arXiv:2006.03627, 2020.">WAR20</a>]</span>, molecular force field prediction <span id="id3">[<a class="reference internal" href="#id111" title="Simon Batzner, Tess E. Smidt, Lixin Sun, Jonathan P. Mailoa, Mordechai Kornbluth, Nicola Molinari, and Boris Kozinsky. Se(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials. arXiv preprint arXiv:2101.03164, 2021.">BSS+21</a>]</span>, molecular energy predictions <span id="id4">[<a class="reference internal" href="#id112" title="Johannes Klicpera, Janek Gro√ü, and Stephan G√ºnnemann. Directional message passing for molecular graphs. arXiv preprint arXiv:2003.03123, 2020.">KGrossGunnemann20</a>]</span>, and 3D molecular structure generation <span id="id5">[<a class="reference internal" href="#id161" title="Victor Garcia Satorras, Emiel Hoogeboom, Fabian B. Fuchs, Ingmar Posner, and Max Welling. E(n) equivariant normalizing flows for molecule generation in 3d. arXiv preprint arXiv:2105.09016, 2021.">SHF+21</a>]</span>.</p>
<p>Alternatives to equivariant networks are training and testing augmentation. Both are powerful methods for many domains and are easy to implement <span id="id6">[<a class="reference internal" href="#id209" title="Connor Shorten and Taghi M Khoshgoftaar. A survey on image data augmentation for deep learning. Journal of big data, 6(1):1‚Äì48, 2019.">SK19</a>]</span>. You can find details in the <a class="reference internal" href="data.html"><span class="doc">Input Data &amp; Equivariances</span></a> chapter. However, augmentation does not work for locally compact symmetry groups (e.g., SO(3)) ‚Äî so you cannot use them for rotationally equivariant data. You can do data transformations like discussed in <a class="reference internal" href="data.html"><span class="doc">Input Data &amp; Equivariances</span></a> to avoid equivariance and only work with invariance.</p>
<p>So why would you study this chapter? I think these ideas are important and incorporating the equivariant layers into other network architectures can dramatically reduce parameter numbers and increase training efficiency.</p>
</section>
<section id="running-this-notebook">
<h2><span class="section-number">10.2. </span>Running This Notebook<a class="headerlink" href="#running-this-notebook" title="Permalink to this headline">¬∂</a></h2>
<p>Click the ¬†<i aria-label="Launch interactive content" class="fas fa-rocket"></i>¬† above to launch this page as an interactive Google Colab. See details below on installing packages.</p>
<div class="dropdown admonition tip">
<p class="admonition-title">Tip</p>
<p>To install packages, execute this code in a new cell.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!pip install dmol-book
</pre></div>
</div>
<p>If you find install problems, you can get the latest working versions of packages used in <a class="reference external" href="https://github.com/whitead/dmol-book/blob/master/package/requirements.txt">this book here</a></p>
</div>
<section id="outline">
<h3><span class="section-number">10.2.1. </span>Outline<a class="headerlink" href="#outline" title="Permalink to this headline">¬∂</a></h3>
<p>We have to lay some mathematical foundations before we can grasp the equations and details of equivariant networks. We‚Äôll start with a brief overview of group theory so we can define the principle of equivariance generally. Then we‚Äôll show how any equivariance can be enforced in a neural network via a generalization of convolutions. Then we‚Äôll visit representation theory to see how to encode groups into matrices.  Then we‚Äôll see how these convolutions can be more easily represented using the generalization of Fourier transforms. Finally, we‚Äôll examine some implementations. Throughout this chapter we‚Äôll see three examples that capture some of the different settings.</p>
</section>
</section>
<section id="group-theory">
<h2><span class="section-number">10.3. </span>Group Theory<a class="headerlink" href="#group-theory" title="Permalink to this headline">¬∂</a></h2>
<p>A modern treatment of group theory can be found in <span id="id7">[<a class="reference internal" href="#id114" title="Anthony Zee. Group theory in a nutshell for physicists. Princeton University Press, 2016.">Zee16</a>]</span>. You can watch a short fun primer video on group theory from <a class="reference external" href="https://www.youtube.com/watch?v=mH0oCDa74tE">3Blue1Brown here</a>.</p>
<p>A group is a general object in mathematics. A group is a set of elements that can be combined in a binary operation whose output is another member of the group. The most common example are the integers. If you combine two integers in a binary operation, the output is another integer. Of course, it depends on the operation (<span class="math notranslate nohighlight">\(1 \div 2\)</span> does not give an integer), so specifically consider addition. Integers are not the example we care about though. We‚Äôre interested in groups of <strong>transformations</strong> that move points in a space. Operations like rotation, scaling, mirroring, or translating of single points. As you read about groups here, remember that the elements of the groups are <em>not</em> numbers or points. The group elements are transformations that act on points in the space. Notice I‚Äôm being a bit nebulous on what the space is for now. Let‚Äôs first define a group:</p>
<div class="admonition-group-definition admonition">
<p class="admonition-title">Group Definition</p>
<p>A group <span class="math notranslate nohighlight">\(G\)</span> is a set of elements (e.g., <span class="math notranslate nohighlight">\(\{a, b, c, i, e\}\)</span>) equipped with a binary operation (<span class="math notranslate nohighlight">\(a\cdot{}b = c\)</span>) whose output is another group element and the following conditions are satisfied:</p>
<ol class="simple">
<li><p><strong>Closure</strong> The output of the binary operation is always a member of the group</p></li>
<li><p><strong>Associativity</strong> <span class="math notranslate nohighlight">\((a\cdot{}b)\cdot{}c = a\cdot{}(b\cdot{}c)\)</span></p></li>
<li><p><strong>Identity</strong> There is a single identity element <span class="math notranslate nohighlight">\(e\)</span> such that <span class="math notranslate nohighlight">\(ex = x \forall x \in G\)</span></p></li>
<li><p><strong>Inverse</strong> There exists exactly one inverse element <span class="math notranslate nohighlight">\(i\)</span> for each <span class="math notranslate nohighlight">\(x\)</span> such that <span class="math notranslate nohighlight">\(xi = e\)</span></p></li>
</ol>
</div>
<p>This is quite a bit of nice structure. We always have an inverse available. Applying the binary operations never accidentally leaves our group. One important property that is missing from this list is <strong>commutativity</strong>. In general, a group is not commutative so that <span class="math notranslate nohighlight">\(a\cdot{}b \neq b\cdot{}a\)</span>. If the group does have this extra property, we call the group <strong>abelian</strong>. Another detail is how big the set is. It can indeed be infinite, which is why the integers or all possible rotations of rotations of points on a sphere can be represented as a group. One notational convenience we‚Äôll make is that the binary operation ‚Äú<span class="math notranslate nohighlight">\(\cdot{}\)</span>‚Äù will just be referred to as ‚Äúdot‚Äù or sometimes multiplication if I get sloppy. The number of elements in a group <span class="math notranslate nohighlight">\(|G|\)</span> is known as the <strong>order</strong>.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>If you multiply two transforms <span class="math notranslate nohighlight">\(a\cdot{}b\)</span>, we always apply <span class="math notranslate nohighlight">\(b\)</span> first and then <span class="math notranslate nohighlight">\(a\)</span>. This is important to remember for non-commutative groups (non-abelian).</p>
</aside>
<p>The point of introducing the groups is so that they can transform elements of our space. This is done through a <strong>group action</strong></p>
<div class="admonition-group-action admonition">
<p class="admonition-title">Group Action</p>
<p>A group action <span class="math notranslate nohighlight">\(\pi(g, v)\)</span> is a mapping from a group <span class="math notranslate nohighlight">\(G\)</span> and a space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> to the space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-8964ea14-a7de-4828-bf25-ce1f42799306">
<span class="eqno">(10.1)<a class="headerlink" href="#equation-8964ea14-a7de-4828-bf25-ce1f42799306" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}
\pi: G\times \mathcal{X}\rightarrow \mathcal{X}
\end{equation}\]</div>
</div>
<aside class="margin sidebar">
<p class="sidebar-title">function arrow</p>
<p><span class="math notranslate nohighlight">\(G\times \mathcal{X}\)</span> means there are two input arguments, one from group <span class="math notranslate nohighlight">\(G\)</span> and one from space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. <span class="math notranslate nohighlight">\(\rightarrow \mathcal{X}\)</span> shows our function outputs a value in the space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>.</p>
</aside>
<p>So a group action takes in two arguments (binary): a group element and a point in a space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and transforms the point to a new one: <span class="math notranslate nohighlight">\(\pi(g, x_0) = x_1\)</span>. This is just a more systematic way of saying it transforms a point. The group action is neither unique to the space nor group. Often we‚Äôll omit the function notation for the group action and just write <span class="math notranslate nohighlight">\(gx = x'\)</span>.</p>
<p>Let‚Äôs introduce our three example groups that we‚Äôll refer to throughout this chapter.</p>
<section id="finite-group-z-6">
<h3><span class="section-number">10.3.1. </span>‚¨° Finite Group <span class="math notranslate nohighlight">\(Z_6\)</span><a class="headerlink" href="#finite-group-z-6" title="Permalink to this headline">¬∂</a></h3>
<p>The first group is about rotations of a hexagon <span class="pasted-inline"><img alt="../_images/Equivariant_84_6.png" src="../_images/Equivariant_84_6.png" /></span>. Our basic group member will be rotating the hexagon enough to shift all the vertices: <span class="pasted-inline"><img alt="../_images/Equivariant_84_0.png" src="../_images/Equivariant_84_0.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_84_1.png" src="../_images/Equivariant_84_1.png" /></span>. Notice I‚Äôve colored the vertices and added a line so we can easily distinguish the orientation of the hexagon. Remember the hexagon, its colors, and if it is actually symmetric have nothing to do with the group. <em>The group elements are transformations we apply to the hexagon</em>.</p>
<p>One group action for this example can use modular arithmetic. If we represent a point in our space as <span class="math notranslate nohighlight">\(\left\{0,\ldots, 5\right\}\)</span> then the rotation transformation is <span class="math notranslate nohighlight">\(x' = x + 1 \;(\bmod\; 6)\)</span>. For example, if we start at <span class="math notranslate nohighlight">\(5\)</span> and rotate, we get back to <span class="math notranslate nohighlight">\(0\)</span>.</p>
<p>Our group must contain our rotation transformation <span class="math notranslate nohighlight">\(r\)</span> and the identity: <span class="math notranslate nohighlight">\(\{e, r\}\)</span>. This set is not closed though: rotating twice <span class="math notranslate nohighlight">\(r\cdot{}r\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_84_0.png" src="../_images/Equivariant_84_0.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_84_1.png" src="../_images/Equivariant_84_1.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_84_2.png" src="../_images/Equivariant_84_2.png" /></span> gives a new group element <span class="math notranslate nohighlight">\(r^2\)</span>. To close the group we need to have <span class="math notranslate nohighlight">\(\{e, r, r^2, r^3, r^4, r^5\}\)</span>.</p>
<p>Is this closed? Consider rotating twice and then five times <span class="math notranslate nohighlight">\(r^5\cdot{}r^2\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_84_0.png" src="../_images/Equivariant_84_0.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_84_2.png" src="../_images/Equivariant_84_2.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_84_1.png" src="../_images/Equivariant_84_1.png" /></span> You can see that this is the same as <span class="math notranslate nohighlight">\(r\)</span>, so <span class="math notranslate nohighlight">\(r^5\cdot{}r^2 = r\)</span>. What about the inverses element? The inverse of <span class="math notranslate nohighlight">\(r\)</span> is <span class="math notranslate nohighlight">\(r^5\)</span>. <span class="math notranslate nohighlight">\(r\cdot{}r^5 = e\)</span>. You can indeed see that each element has an inverse (<span class="math notranslate nohighlight">\(e\)</span> is its own inverse).</p>
<p>In general, we can write out the group as a multiplication table that conveys all group elements and defines the output of all binary outputs:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{l|cccccr}
&amp; e &amp; r &amp; r^2 &amp; r^3 &amp; r^4 &amp; r^5\\
\hline
e &amp; e &amp; r &amp; r^2 &amp; r^3 &amp; r^4 &amp; r^5\\
r &amp; r &amp; r^2 &amp; r^3 &amp; r^4 &amp; r^5 &amp; e\\
r^2 &amp; r^2 &amp; r^3 &amp; r^4 &amp; r^5 &amp; e &amp; r\\
r^3 &amp; r^3 &amp; r^4 &amp; r^5 &amp; e &amp; r &amp; r^2\\
r^4 &amp; r^4 &amp; r^5 &amp; e &amp; r &amp; r^2 &amp; r^3\\
r^5 &amp; r^5 &amp; e &amp; r &amp; r^2 &amp; r^3 &amp; r^4\\
\end{array}
\end{split}\]</div>
<p>You can also see that the group is abelian (commutative). For example, <span class="math notranslate nohighlight">\(r\cdot{}r^3 = r^3\cdot{}r\)</span>.</p>
<p>This kind of table is called a <a class="reference external" href="https://en.wikipedia.org/wiki/Cayley_table"><strong>Cayley table</strong></a>. Although it doesn‚Äôt matter for this example, we‚Äôll see later that the order of look-up matters. Specifically if our group is non-abelian. <em>The row factor comes first and the column factor second</em>. So <span class="math notranslate nohighlight">\(r\cdot{}r^5\)</span> means we look at row <span class="math notranslate nohighlight">\(r\)</span> and column <span class="math notranslate nohighlight">\(r^5\)</span> to get the group element, which in this case is <span class="math notranslate nohighlight">\(e\)</span>.</p>
<p>This group of rotations is an example of a <strong>cyclic group</strong> and is isomorphic (same transformations, but operates on different objects) to integers modulo 6. Meaning, you could view rotation <span class="math notranslate nohighlight">\(r^n\)</span> as operating on integers <span class="math notranslate nohighlight">\((x + n) \textrm{mod}\, 6\)</span>. Cyclic groups are written as <span class="math notranslate nohighlight">\(Z_n\)</span>, so this group is <span class="math notranslate nohighlight">\(Z_6\)</span>.</p>
</section>
<section id="p4m">
<h3><span class="section-number">10.3.2. </span>‚ñ© p4m<a class="headerlink" href="#p4m" title="Permalink to this headline">¬∂</a></h3>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>p4m strictly speaking only includes integer translations but many of the principles apply for continuous infinite groups (locally compact) and integer (countably) infinite groups</p>
</aside>
<p>The second group contains translation, 90¬∞ rotations, and  horizontal/vertical mirroring. We‚Äôre now operating on real numbers <span class="math notranslate nohighlight">\(x,y\)</span>, so we‚Äôre in <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span>. Let‚Äôs ignore the translation for now and just consider mirroring (<span class="math notranslate nohighlight">\(s\)</span>) and rotation by 90¬∞ (<span class="math notranslate nohighlight">\(r\)</span>) about the origin. What powers of <span class="math notranslate nohighlight">\(r\)</span> and <span class="math notranslate nohighlight">\(s\)</span> do we need to have a closed group? Considering rotations alone first, like last time we should only need up to <span class="math notranslate nohighlight">\(r^3\)</span>. Here are the rotations visually: <span class="pasted-inline"><img alt="../_images/Equivariant_84_8.png" src="../_images/Equivariant_84_8.png" /></span>, <span class="pasted-inline"><img alt="../_images/Equivariant_84_12.png" src="../_images/Equivariant_84_12.png" /></span>, <span class="pasted-inline"><img alt="../_images/Equivariant_84_16.png" src="../_images/Equivariant_84_16.png" /></span>, <span class="pasted-inline"><img alt="../_images/Equivariant_84_20.png" src="../_images/Equivariant_84_20.png" /></span> What about mirroring on horizontal/vertical? Mirroring along the horizontal axis: <span class="pasted-inline"><img alt="../_images/Equivariant_84_8.png" src="../_images/Equivariant_84_8.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_84_18.png" src="../_images/Equivariant_84_18.png" /></span> is actually the same as rotating twice and then mirroring along the vertical. In fact, you only need to have mirroing along one axis. We‚Äôll choose the vertical axis by convention and denote that as <span class="math notranslate nohighlight">\(s\)</span>.</p>
<p>We can build the group action piece by piece. The group action for rotation can be represented as a 2D rotation matrix acting a point <span class="math notranslate nohighlight">\((x, y)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[\begin{array}{lr}
\cos\frac{k2\pi}{4} &amp; -\sin\frac{k2\pi}{4}\\
\sin\frac{k2\pi}{4} &amp; \cos\frac{k2\pi}{4}\\
\end{array}\right]
\left[\begin{array}{c}
x\\
y\\
\end{array}\right]
,\, k \in \left\{0, 1, 2, 3\right\}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(k\)</span> can allow us to do two rotations at once (<span class="math notranslate nohighlight">\(k = 2\)</span>) or the identity (<span class="math notranslate nohighlight">\(k = 0\)</span>). The vertical axis mirror action can be represented by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[\begin{array}{lr}
-1 &amp; 0\\
0 &amp; 1\\
\end{array}\right]
\left[\begin{array}{c}
x\\
y\\
\end{array}\right]
\end{split}\]</div>
<p>These two group actions can be ordered to correctly represent rotation then mirroring or vice-versa.</p>
<p>Now is this closed with the group elements <span class="math notranslate nohighlight">\(\{e, r, r^2, r^3, s\}\)</span>? Visually we have  <span class="pasted-inline"><img alt="../_images/Equivariant_84_8.png" src="../_images/Equivariant_84_8.png" /></span>, <span class="pasted-inline"><img alt="../_images/Equivariant_84_12.png" src="../_images/Equivariant_84_12.png" /></span>, <span class="pasted-inline"><img alt="../_images/Equivariant_84_16.png" src="../_images/Equivariant_84_16.png" /></span>, <span class="pasted-inline"><img alt="../_images/Equivariant_84_20.png" src="../_images/Equivariant_84_20.png" /></span>, <span class="pasted-inline"><img alt="../_images/Equivariant_84_10.png" src="../_images/Equivariant_84_10.png" /></span>? No. Consider <span class="math notranslate nohighlight">\(r^2\cdot{}s\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_84_8.png" src="../_images/Equivariant_84_8.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_84_10.png" src="../_images/Equivariant_84_10.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_84_18.png" src="../_images/Equivariant_84_18.png" /></span> which is not an element. To close the group, we need <span class="math notranslate nohighlight">\(\{e, r, r^2, r^3, s, rs, r^2s, r^3s\}\)</span>. The multiplication table (which defines the elements too) is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{l|cccccccr}
&amp; e &amp; r &amp; r^2 &amp; r^3 &amp; s &amp; rs &amp; r^2s &amp; r^3s\\
\hline
e &amp; e &amp; r &amp; r^2 &amp; r^3 &amp; s &amp; rs &amp; r^2s &amp; r^3s\\
r &amp; r &amp; r^2 &amp; r^3 &amp; e &amp; rs &amp; r^2s &amp; r^3s &amp; s\\
r^2 &amp; r^2 &amp; r^3 &amp; e &amp; r &amp; r^2s &amp; r^3s &amp; s &amp; rs\\
r^3 &amp; r^3 &amp; e &amp; r &amp; r^2 &amp; r^3s &amp; s &amp; rs &amp; r^2s\\
s &amp; s &amp; r^3s &amp; r^2s &amp; rs &amp; e &amp; r^3 &amp; r^2 &amp; r\\
rs &amp; rs &amp; s &amp; r^3s &amp; r^2s &amp; r &amp; e &amp; r^3 &amp; r^2\\
r^2s &amp; r^2s &amp; rs &amp; s &amp; r^3s &amp; r^2 &amp; r &amp; e &amp; r^3\\
r^3s &amp; r^3s &amp; r^2s &amp; rs &amp; s &amp; r^3 &amp; r^2 &amp; r &amp; e\\
\end{array}
\end{split}\]</div>
<p>This is a <a class="reference external" href="https://en.wikipedia.org/wiki/Cayley_table"><strong>Cayley table</strong></a>. Remember <em>The row factor comes first and the column factor second</em>. So <span class="math notranslate nohighlight">\(rs\cdot{}r^3\)</span> means we look at row <span class="math notranslate nohighlight">\(rs\)</span> and column <span class="math notranslate nohighlight">\(r^3\)</span> to get the group element, which in this case is <span class="math notranslate nohighlight">\(r^2s\)</span>.</p>
<p>As you can see from the Cayley table, the group is closed. Remember, elements like <span class="math notranslate nohighlight">\(rs\)</span> are not a binary operation. They are group elements, hence the missing binary operation symbol. We also see that the group is not commutative. <span class="math notranslate nohighlight">\(r\cdot{}s\)</span> is <span class="pasted-inline"><img alt="../_images/Equivariant_84_8.png" src="../_images/Equivariant_84_8.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_84_10.png" src="../_images/Equivariant_84_10.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_84_22.png" src="../_images/Equivariant_84_22.png" /></span>, so <span class="math notranslate nohighlight">\(r\cdot{}s = rs\)</span> as expected. However, <span class="math notranslate nohighlight">\(s\cdot{}r\)</span> is <span class="pasted-inline"><img alt="../_images/Equivariant_84_8.png" src="../_images/Equivariant_84_8.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_84_12.png" src="../_images/Equivariant_84_12.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_84_14.png" src="../_images/Equivariant_84_14.png" /></span>, which is the group element <span class="math notranslate nohighlight">\(r^3s\)</span>.</p>
<p>We can also read the inverses off the table. For example, the inverse of <span class="math notranslate nohighlight">\(r\)</span> is the column which gives the identity element: <span class="math notranslate nohighlight">\(r^3\)</span>. This group is known as the dihedral group 4 <span class="math notranslate nohighlight">\(D_4\)</span>. It has order 8.</p>
<p>Now consider the translation group elements. For simplicity, let‚Äôs only consider integer translations. We can label them as <span class="math notranslate nohighlight">\(t_{w,h}\)</span>. So <span class="math notranslate nohighlight">\(t_{3,4}\)</span> means translate by <span class="math notranslate nohighlight">\(x + 3\)</span> and <span class="math notranslate nohighlight">\(y + 4\)</span>. Is this a proper group? Certainly it associative, there is an identity <span class="math notranslate nohighlight">\(t_{0,0}\)</span> and an inverse for each element <span class="math notranslate nohighlight">\(t_{-x, -y}\)</span>. What about closure? Yes, since translating twice is equivalent to one larger translation: <span class="math notranslate nohighlight">\(t_{w,h}\cdot{}t_{w', h'} = t_{w + w', h + h'}\)</span>. This expression also shows group action for translation.</p>
<p>What about when we combine with our other elements from the <span class="math notranslate nohighlight">\(D_4\)</span> group? Consider the product <span class="math notranslate nohighlight">\(r\cdot{}t_{3,4}\)</span>. This means translating by <span class="math notranslate nohighlight">\((3,4)\)</span> and then rotating by 90¬∞ about the origin. If you consider this acting on a single point <span class="math notranslate nohighlight">\((0,0)\)</span>, you could get <span class="math notranslate nohighlight">\((0,0) \rightarrow (3,4) \rightarrow (-4,3)\)</span>. What element of our group would this represent? At first it seems like it could be <span class="math notranslate nohighlight">\(t_{-3,4}\)</span>. However, <span class="math notranslate nohighlight">\(t_{-3,4}\)</span> would only work specifically for starting at <span class="math notranslate nohighlight">\((0,0)\)</span>. If you started at <span class="math notranslate nohighlight">\((1,1)\)</span>, you would get to <span class="math notranslate nohighlight">\((-4,5)\)</span> with <span class="math notranslate nohighlight">\(r\cdot{}t_{3,4}\)</span> and <span class="math notranslate nohighlight">\((-2,5)\)</span> with <span class="math notranslate nohighlight">\(t_{-3,4}\)</span>. To be correct for <em>any point</em>, we need a different group element. So the product <span class="math notranslate nohighlight">\(r\cdot{}t_{3,4}\)</span> actually cannot be a product but instead must be a group element. In fact, our new combined group is just going to be <span class="math notranslate nohighlight">\(ab\)</span> where <span class="math notranslate nohighlight">\(a\)</span> is an element from <span class="math notranslate nohighlight">\(D_4\)</span> and <span class="math notranslate nohighlight">\(b\)</span> is a translation. Thus <span class="math notranslate nohighlight">\(r\cdot{}t_{3,4} = rt_{3,4}\)</span>.</p>
<p>Combing these two groups, the translation and <span class="math notranslate nohighlight">\(D_4\)</span>, is an example of a <strong>semidirect product</strong>. A semidirect product just means that we create a new group by combining all possible group elements. There is some machinery for this, like the identity element in our new group is something like <span class="math notranslate nohighlight">\(et_{0,0}\)</span>, and it has some other structure. It is called semidirect, instead of direct, because we can actually mix our group elements. The elements both act on points in the same space (<span class="math notranslate nohighlight">\(x,y\)</span> plane), so this makes sense. Another condition is that we can only have a semidirect product when one subgroup is normal and the translation subgroup is the normal subgroup. It is coincidentally abelian, but these two properties are not always identical. This semidirect product group is called p4m.</p>
<p>Below, is an optional section that formalizes the idea of combining these two groups into one larger group.</p>
<div class="admonition-normal-subgroup admonition">
<p class="admonition-title">Normal Subgroup</p>
<p>A normal subgroup is a group of elements <span class="math notranslate nohighlight">\(n\)</span> from the group <span class="math notranslate nohighlight">\(G\)</span> called <span class="math notranslate nohighlight">\(N\)</span>. Each <span class="math notranslate nohighlight">\(n \in N\)</span> should have the property that <span class="math notranslate nohighlight">\(g\cdot{}n\cdot{}g^{-1}\)</span> gives an element in <span class="math notranslate nohighlight">\(N\)</span> for any <span class="math notranslate nohighlight">\(g\)</span>.</p>
</div>
<p>This does not mean <span class="math notranslate nohighlight">\(g\cdot{}n\cdot{}g^{-1} = n\)</span>, but instead that <span class="math notranslate nohighlight">\(g\cdot{}n\cdot{}g^{-1} = n'\)</span> where <span class="math notranslate nohighlight">\(n'\)</span> is some other element in <span class="math notranslate nohighlight">\(N\)</span>. For example, in p4m the translations form a normal subgroup. Rotating, translating, then doing the inverse of the rotation is equivalent to some translation. Notice that <span class="math notranslate nohighlight">\(D_4\)</span> is not a normal subgroup of p4m. If you do an inverse translation, rotate, then do a translation you may not have something equivalent to a rotation. It may be strange that we‚Äôre talking about the group p4m when we haven‚Äôt yet described how it‚Äôs defined (identity, inverse, binary op). We‚Äôll do that with the semidirect product and then we could go back and verify that the translations are a normal subgroup more rigorously. I do not know the exact connection, but it seems that normal subgroups are typically abelian.</p>
<div class="admonition-semidirect-product admonition">
<p class="admonition-title">Semidirect Product</p>
<p>Given a normal subgroup of <span class="math notranslate nohighlight">\(G\)</span> called <span class="math notranslate nohighlight">\(N\)</span> and a subgroup <span class="math notranslate nohighlight">\(H\)</span>, we can define <span class="math notranslate nohighlight">\(G\)</span> using the semidirect product. Each element in <span class="math notranslate nohighlight">\(G\)</span> is a tuple of two elements in <span class="math notranslate nohighlight">\(N, H\)</span> written as <span class="math notranslate nohighlight">\((n, h)\)</span>. The identity is <span class="math notranslate nohighlight">\((e_n, e_h)\)</span> and the binary operation is:</p>
<div class="amsmath math notranslate nohighlight" id="equation-c5af91a1-6d20-4d61-9e61-d908b6533176">
<span class="eqno">(10.2)<a class="headerlink" href="#equation-c5af91a1-6d20-4d61-9e61-d908b6533176" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}
(n_1, h_1) \cdot (n_2, h_2) = (n_1\cdot\phi(h_1)(n_2), h_1\cdot{}h_2)
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\phi(h)(n)\)</span> is the conjugation of <span class="math notranslate nohighlight">\(n\)</span> <span class="math notranslate nohighlight">\(\phi(h)(n) = h\cdot{}n\cdot{}h^{-1}\)</span>. When a transform <span class="math notranslate nohighlight">\((n,h)\)</span> is applied, we follow the normal convention that <span class="math notranslate nohighlight">\(h\)</span> is applied first followed by <span class="math notranslate nohighlight">\(n\)</span>.</p>
</div>
<p>We are technically doing an outer semidirect product: combining them under the assumption that both <span class="math notranslate nohighlight">\(D_4\)</span> and <span class="math notranslate nohighlight">\(T\)</span> are part of a larger group which contains both. This is a bit of a semantic detail, but they are actually both part of <span class="math notranslate nohighlight">\(p4m\)</span> and a larger group called the affine group which includes, rotation, shear, translation, mirror, and scale operations on points. You could also argue they are part of groups which can be represented by 3x3 invertible matrices. Thus, you can combine these and get something that is still smaller than their larger containing group (<span class="math notranslate nohighlight">\(p4m\)</span> is smaller than all affine transformations).</p>
<p>One consequence of the semidirect product is that if you have a group element <span class="math notranslate nohighlight">\((n,h)\)</span> but want to instead apply <span class="math notranslate nohighlight">\(n\)</span> first (instead of <span class="math notranslate nohighlight">\(h\)</span>), you can use the binary operation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-9b0dcd37-f409-4074-a4c2-8d2e5176db2c">
<span class="eqno">(10.3)<a class="headerlink" href="#equation-9b0dcd37-f409-4074-a4c2-8d2e5176db2c" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}
(e_n, h) \cdot (n, e_h) = (e_n\cdot\phi(h)(n), h\cdot{}e_h) = (\phi(h)(n), h)
\end{equation}\]</div>
<p>so <span class="math notranslate nohighlight">\(\phi(h)(n)\)</span> somehow captures the effect of switching the order applying elements from <span class="math notranslate nohighlight">\(H\)</span> and <span class="math notranslate nohighlight">\(N\)</span>. In our case, this means swapping the order of rotation/mirroring and translation.</p>
<p>To show what effect the semidirect product has in p4m, we can clean-up our example above about <span class="math notranslate nohighlight">\(r\cdot{}t_{3,4}\)</span>. We should write the first element of this binary product <span class="math notranslate nohighlight">\(r\)</span> as a tuple of group elements: one from the <span class="math notranslate nohighlight">\(D_4\)</span> and one from the translations. Since there is no translation for <span class="math notranslate nohighlight">\(r\)</span>, we use the identity. Thus we write <span class="math notranslate nohighlight">\(r\)</span> as <span class="math notranslate nohighlight">\((t_{0,0}, r)\)</span> in our semidirect product group p4m. Note that the normal subgroup comes first (applied last) by convention. Similarly, <span class="math notranslate nohighlight">\(t_{3,4}\)</span> is written as <span class="math notranslate nohighlight">\((t_{3,4}, e)\)</span>. Our equation becomes:</p>
<div class="math notranslate nohighlight">
\[
(t_{0,0}, r)\cdot(t_{3,4}, e) = (t_{0,0}\cdot\phi(r)(t_{3,4}), r\cdot{}e) = (t_{0,0}\cdot\phi(r)(t_{3,4}), r)
\]</div>
<p>where <span class="math notranslate nohighlight">\(\phi\)</span> is the automorphism that distinguishes a semidirect product from a direct product. The direct product has <span class="math notranslate nohighlight">\(\phi(h)(n) = n\)</span> so that the binary operation for the direct product group is just the element-wise binary products. <span class="math notranslate nohighlight">\(\phi(h)(n) = hnh^{-1}\)</span> for semidirect products. In our equation, this means <span class="math notranslate nohighlight">\(\phi(r)(t_{3,4}) = r\cdot{}t_{3,4}\cdot{}r^3\)</span>. Substituting this and using the fact that both groups have the same binary operation (matrix multiplication, as we‚Äôll see shortly):</p>
<div class="math notranslate nohighlight">
\[
(t_{0,0}\phi(r)(t_{3,4}), r) = (r\cdot{}t_{3,4}\cdot{}r^3, r) = r\cdot{}t_{3,4}\cdot{}r^3\cdot r = r\cdot{}t_{3,4}
\]</div>
<p>Thus we‚Äôve proved that translating by <span class="math notranslate nohighlight">\(3,4\)</span> followed by rotating can be expressed as <span class="math notranslate nohighlight">\(r\cdot{}t_{3,4}\)</span>, which seems like a lot of work for an obvious result. I won‚Äôt cover the semidirect product of the group action, but we‚Äôll see that we do not necessarily need to build a group action encapsulating both translation and rotation/mirroring.</p>
</section>
<section id="so-3-group">
<h3><span class="section-number">10.3.3. </span>‚öΩ SO(3) Group<a class="headerlink" href="#so-3-group" title="Permalink to this headline">¬∂</a></h3>
<p>SO(3) is the group for analyzing 3D point clouds like trajectories or crystal structures (with no other symmetries). SO(3) is the group of all rotations about the origin in 3D. The group is non-abelian because rotations in 3D are not commutative. The group order is infinite, because you can rotate in this group by any angle (or sets of angles). If you are interested in allowing translations, you can use SE(3) which is the semidirect product of SO(3) and the translation group (like p4m), which is a normal subgroup.</p>
<p>The SO(3) name is a bit strange. SO stands for ‚Äúspecial orthogonal‚Äù which are two properties of square matrices. In this case, the matrices are <span class="math notranslate nohighlight">\(3\times3\)</span>. Orthogonal  means the columns sum to one and special means the determinant is 1. Interestingly, all rotations in 3D around the origin are also the SO(3) matrices.</p>
<p>One detail is that since we‚Äôre rotating (no scale or translation) the distance to origin will not change. We cannot move the radius. The group action is the product of 3 3D rotation matrices (using <a class="reference external" href="https://en.wikipedia.org/wiki/Euler_angles">Euler angles</a>) <span class="math notranslate nohighlight">\(R_z(\alpha)R_y(\beta)R_z(\gamma)\)</span> where <span class="math notranslate nohighlight">\(\alpha,\gamma \in [0, 2\pi], \beta \in [0, \pi]\)</span> and</p>
<div class="math notranslate nohighlight">
\[\begin{split}
R_z(\theta) = \left[\begin{array}{lcr}
\cos\theta &amp; -\sin\theta &amp; 0\\
\sin\theta &amp; \cos\theta &amp; 0\\
0 &amp; 0 &amp; 1\\
\end{array}\right]
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
R_y(\theta) = \left[\begin{array}{lcr}
\cos\theta &amp; 0 &amp; \sin\theta \\
0 &amp; 1 &amp; 0\\
-\sin\theta &amp;  0 &amp; \cos\theta\\
\end{array}\right]
\end{split}\]</div>
</section>
<section id="groups-on-spaces">
<h3><span class="section-number">10.3.4. </span>Groups on Spaces<a class="headerlink" href="#groups-on-spaces" title="Permalink to this headline">¬∂</a></h3>
<p>We‚Äôve defined transforms and their relationships to one another via group theory. Now we need to actually connect the transforms to a space. It is helpful to think about the space as Euclidean with a concept of distance and coordinates, but we‚Äôll see that this is not required. Our space could be vertices on a graph or integers or classes. There are <em>some</em> requirements though. The first is that our space must be <strong>homogeneous</strong> (for the purposes of this chapter). Homogeneous means that from any point in our space <span class="math notranslate nohighlight">\(x\)</span> we can reach any other point with a transform <span class="math notranslate nohighlight">\(g\)</span> from our group <span class="math notranslate nohighlight">\(G\)</span>. The second requirement is that if our group is infinite, the space must <strong>locally compact</strong>. This is a concept from topology and we won‚Äôt really ever be troubled by it. Most spaces we‚Äôll see in chemistry or materials science (Euclidean spaces) are locally compact.</p>
<aside class="margin sidebar">
<p class="sidebar-title">Lie group</p>
<p>If the group transforms are further smooth and have smooth inverses, the group (and associated space) are called a <strong>lie group</strong>.</p>
</aside>
<div class="tabbed-set docutils">
<input checked="checked" id="341d0333-ab2d-49aa-b171-e0151dd8ca0b" name="b1960d90-987a-4d75-a919-6ac242f1de34" type="radio">
</input><label class="tabbed-label" for="341d0333-ab2d-49aa-b171-e0151dd8ca0b">
‚¨° Finite Group <span class="math notranslate nohighlight">\(Z_6\)</span> </label><div class="tabbed-content docutils">
<p>The space is homogeneous because our group includes ‚Äúcompound‚Äù rotations like <span class="math notranslate nohighlight">\(r^4\)</span>. This is a finite group, so we do not require the space to be compact.</p>
</div>
<input id="c07fd82d-936d-473b-a4a7-11a96ce6b311" name="b1960d90-987a-4d75-a919-6ac242f1de34" type="radio">
</input><label class="tabbed-label" for="c07fd82d-936d-473b-a4a7-11a96ce6b311">
‚ñ© Locally Compact p4m</label><div class="tabbed-content docutils">
<p>The space is homogeneous since we can use a translation to get to any other point. The space is locally compact because we are in 2D Euclidean geometry.</p>
</div>
<input id="e7bec989-b51d-4edb-a844-58bcd55cde56" name="b1960d90-987a-4d75-a919-6ac242f1de34" type="radio">
</input><label class="tabbed-label" for="e7bec989-b51d-4edb-a844-58bcd55cde56">
‚öΩ SO(3) Group</label><div class="tabbed-content docutils">
<p>The space is homogeneous because we restrict ourselves to being on the sphere. The space is locally compact because we are in 3D Euclidean geometry.</p>
</div>
</div>
<p>The requirement of space being homogeneous is fairly strict. It means we cannot work with <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span> with a finite group like mirror and fixed rotations (i.e., p4m without translations). For example, going from <span class="math notranslate nohighlight">\(x = (0,0)\)</span> to <span class="math notranslate nohighlight">\(x = (1,1)\)</span> cannot be done with rotations/mirror group elements alone. As you can see, working in a Euclidean space thus requires a locally compact group. Similarly, a finite group implies a finite space because of the homogeneous requirement.</p>
<p>This may seem like a ton of work. We could have just started with <span class="math notranslate nohighlight">\(xyz\)</span> coordinates and rotation matrices. Please continue to wait though, we‚Äôre about to see something incredible.</p>
</section>
</section>
<section id="equivariance-definition">
<h2><span class="section-number">10.4. </span>Equivariance Definition<a class="headerlink" href="#equivariance-definition" title="Permalink to this headline">¬∂</a></h2>
<p>You should be thinking now about how we can define equivariance using our new groups. That‚Äôs where we‚Äôre headed. We need to do a bit of work now to ‚Äúlift‚Äù neural networks and our features into the framework we‚Äôre building. First, in <a class="reference internal" href="data.html"><span class="doc">Input Data &amp; Equivariances</span></a> we defined our features as being composed of tuples <span class="math notranslate nohighlight">\((\vec{r}_i, \vec{x}_i)\)</span> where <span class="math notranslate nohighlight">\(\vec{r}_i\)</span> is a spatial point and <span class="math notranslate nohighlight">\(\vec{x}_i\)</span> are the features at that point. Let‚Äôs now view these input data as functions, defined as <span class="math notranslate nohighlight">\(f(\vec{r}) = \vec{x}\)</span> and assume if a point <span class="math notranslate nohighlight">\(\vec{r}'\)</span> isn‚Äôt in our training data then <span class="math notranslate nohighlight">\(f(\vec{r}') = \vec{0}\)</span>. More formally, our training data is a function <span class="math notranslate nohighlight">\(f:\mathcal{X} \rightarrow \mathbb{R}^n\)</span> that maps from our homogeneous space <span class="math notranslate nohighlight">\(\mathcal{x}\)</span> to real vector (or complex vectors) of dimension <span class="math notranslate nohighlight">\(n\)</span>.</p>
<p>We have promoted our data into a function and now a neural network can no longer be just function since its input is a function. Our neural network will be also promoted to a <strong>linear map</strong>, which has an input of a function and an output of a function. Formally, our neural network is now <span class="math notranslate nohighlight">\(\psi: f(\mathcal{X}) \rightarrow f'(\mathcal{X})\)</span>. Notice the input and output spaces of the functions may not be the same (we may input a molecule 3D and output a 1D scalar for energy). Linear maps are also called <strong>operators</strong>, depending on which branch of mathematics you‚Äôre in.</p>
<p>The last piece of equivariance is to promote our group elements, which transform points, to work on functions.</p>
<div class="admonition-g-function-transform-definition admonition">
<p class="admonition-title">G-Function Transform Definition</p>
<p>An element <span class="math notranslate nohighlight">\(g\)</span> of group <span class="math notranslate nohighlight">\(G\)</span> on the homogeneous space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> can act on a function <span class="math notranslate nohighlight">\(f:\mathcal{X}\rightarrow \mathbb{R}^n\)</span> via the group transform linear map <span class="math notranslate nohighlight">\(\mathbb{T}_g: f(\mathcal{X}) \rightarrow f'(\mathcal{X})\)</span> defined as</p>
<div class="amsmath math notranslate nohighlight" id="equation-67a6751a-3c67-4ce7-9d09-70ed7227fbf5">
<span class="eqno">(10.4)<a class="headerlink" href="#equation-67a6751a-3c67-4ce7-9d09-70ed7227fbf5" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}
f'(gx) = f(x) \Rightarrow f'(x) = f(g^{-1}x)
\end{equation}\]</div>
</div>
<p>This definition takes a moment to think about. Consider a translation of an image. You want to move an image to the left by 10 pixels, so <span class="math notranslate nohighlight">\(g = t_{10,0}\)</span>. The image is defined by the function <span class="math notranslate nohighlight">\(f(x,y) = (r, g, b)\)</span>, where <span class="math notranslate nohighlight">\(r,g,b\)</span> is the color. We want <span class="math notranslate nohighlight">\(T_g f(x, y)\)</span>. Without knowing about groups, you can intuit that translating can be done by creating a new function <span class="math notranslate nohighlight">\(f'(x', y') = f(x - 10, y)\)</span>. Notice that the inverse of <span class="math notranslate nohighlight">\(g^{-1} = t_{-10, 0}\)</span> acts on the points, not <span class="math notranslate nohighlight">\(g\)</span>. Recall that a group requires there to be an inverse for any group element.</p>
<p>Now we have all the pieces to define an equivariant neural network:</p>
<div class="admonition-equivariant-neural-network-definition admonition">
<p class="admonition-title">Equivariant Neural Network Definition</p>
<p>Given a group <span class="math notranslate nohighlight">\(G\)</span> that has actions on two homogeneous space <span class="math notranslate nohighlight">\(\mathcal{X_1}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{X_2}\)</span>, a G-equivariant neural network is a linear map <span class="math notranslate nohighlight">\(\psi: f(\mathcal{X_1}) \rightarrow f'(\mathcal{X_2})\)</span> that has the property<span id="id8">[<a class="reference internal" href="#id104" title="Risi Kondor and Shubhendu Trivedi. On the generalization of equivariance and convolution in neural networks to the action of compact groups. In International Conference on Machine Learning, 2747‚Äì2755. 2018.">KT18</a>]</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-44b32912-009d-47ae-ae9f-9c810834c5c7">
<span class="eqno">(10.5)<a class="headerlink" href="#equation-44b32912-009d-47ae-ae9f-9c810834c5c7" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}
\psi\left[\mathbb{T}_g f(x)\right] = \mathbb{T'}_{g}\psi\left[f(x)\right]\;\forall\, f(x)
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbb{T}_g\)</span> and <span class="math notranslate nohighlight">\(\mathbb{T}'_g\)</span> are G-function transforms on the two spaces. If <span class="math notranslate nohighlight">\(\mathbb{T}'_g = \textrm{id}\)</span>, meaning the transform is the identity in the output space regardless of <span class="math notranslate nohighlight">\(g\)</span>, then <span class="math notranslate nohighlight">\(\psi\)</span> is a G-invariant neural network.</p>
</div>
<p>The definition means that we get the same output if we transform the input function to the neural network or transform the output (in the equivariant case). In a specific example, if we rotate the input by 90 degrees, that‚Äôs the same result as rotating the output by 90 degrees. Take a moment to ensure that matches your idea of what equivariance means. After all this math, we‚Äôve generalized equivariance to arbitrary spaces and groups.</p>
<p>What the two input and output spaces? It‚Äôs easiest to think about them as the same space for equivariant neural networks. For an invariant, the output space is typically a scalar. Another example for an invariant one could be aligning a molecular structure to a reference. The neural network should align to the same reference regardless of how the input is transformed.</p>
</section>
<section id="g-equivariant-convolution-layers">
<h2><span class="section-number">10.5. </span>G-Equivariant Convolution Layers<a class="headerlink" href="#g-equivariant-convolution-layers" title="Permalink to this headline">¬∂</a></h2>
<p>Recall that a neural network is made-up of a linear part (e.g., $\vec{h} = \mathbf{W}\vec{x} + \vec{b}) and a non-linearity.  Kondor and Trivedi showed that there is <em>only one</em> way to make a G-equivariant neural network is to make the linear part:</p>
<div class="admonition-g-equivariant-convolution-theorem admonition">
<p class="admonition-title">G-Equivariant Convolution Theorem</p>
<p>A neural network layer (linear map) <span class="math notranslate nohighlight">\(\psi\)</span> is G-equivariant if and only if its form is a convolution operator <span class="math notranslate nohighlight">\(*\)</span></p>
<div class="amsmath math notranslate nohighlight" id="equation-383c9b27-803a-4428-8889-c5aef1b78537">
<span class="eqno">(10.6)<a class="headerlink" href="#equation-383c9b27-803a-4428-8889-c5aef1b78537" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}

$$
\psi(f) = (f * \omega)(u) = \sum_{g \in G} f\uparrow^G\left(ug^{-1}\right)\omega\uparrow^G\left(g\right)
$$ (disc-conv)

where $f: H \rightarrow \mathbb{R}^n$ and $\omega: H' \rightarrow \mathbb{R}^n$ are functions of quotient spaces $H$ and $H'$. If the group $G$ is locally compact (infinite elements), then the convolution operator is

\begin{equation}
\label{cont-conv}
\psi(f) = (f * \omega)(u) = \int_G f\uparrow^G\left(ug^{-1}\right)\omega\uparrow^G\left(g\right)\,d\mu(g)
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu\)</span> is the group Haar measure. A <a class="reference external" href="https://en.wikipedia.org/wiki/Haar_measure">Haar measure</a> is a generalization of the familiar integrand factor you see when doing integrals in polar coordinates or spherical coordinates.</p>
</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>This is a strong theorem. It says there is only one way to achieve equivariance in a neural network. This may seem counter-intuitive since there are many competing approaches to convolutions. These other approaches are actually equivalent to a convolution; just it can be hard to notice.</p>
</aside>
<p>As you can see from the theorem, we must introduces more new concepts. The first important detail is that all our functions are over our group elements (technically the quotient space <span class="math notranslate nohighlight">\(G / H_0\)</span>), not our space. This should seem strange. We will easily fix this because there is a (bijective) way to assign one group element to each point in the space. The second detail is the <span class="math notranslate nohighlight">\(f \uparrow^G\)</span>. The order of the group <span class="math notranslate nohighlight">\(G\)</span> is greater than or equal to the number of points in our space, so if the function is defined on our space, we must ‚Äúlift‚Äù it up to the group <span class="math notranslate nohighlight">\(G\)</span> which has more elements. The last detail is the point about <strong>quotient spaces</strong>. Quotient spaces are how we cut-up our group <span class="math notranslate nohighlight">\(G\)</span> into subgroups so that one has the same order as the number of points in our space. Below I detail these new concepts just enough so that we can implement and understand these convolutions.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>To actually learn, you need to put in a nonlinearity after the convolution. A simple (and often used) case is to just use a standard non-linear function like ReLU pointwise (applied to each term in <span class="math notranslate nohighlight">\(g \in G\)</span> sum individually). We‚Äôll look at more complex examples below for the continuous case.</p>
</div>
</section>
<section id="converting-between-space-and-group">
<h2><span class="section-number">10.6. </span>Converting between Space and Group<a class="headerlink" href="#converting-between-space-and-group" title="Permalink to this headline">¬∂</a></h2>
<p>Let‚Äôs see how we can convert between functions on the space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and functions on the group <span class="math notranslate nohighlight">\(G\)</span>. <span class="math notranslate nohighlight">\(|G| \geq |\mathcal{X}|\)</span> (<span class="math notranslate nohighlight">\(|G|\)</span> is number of elements) because the space is homogeneous, so it is rare that we can uniquely replace each point in space with a group in <span class="math notranslate nohighlight">\(G\)</span>. Instead, we will construct a partitioning of <span class="math notranslate nohighlight">\(G\)</span> into <span class="math notranslate nohighlight">\(|\mathcal{X}|\)</span> sets called a quotient space <span class="math notranslate nohighlight">\(G / H\)</span> such that <span class="math notranslate nohighlight">\(|G / H| = |\mathcal{X}|\)</span>. It turns out, there is a well-studied approach to arranging elements in a group called <strong>cosets</strong>. Constructing cosets is a two-step process. First we define a subgroup <span class="math notranslate nohighlight">\(H\)</span>. A <strong>subgroup</strong> means it is itself a group; it has identities and inverses. We cannot accidentally leave <span class="math notranslate nohighlight">\(H\)</span>, <span class="math notranslate nohighlight">\(h_1\cdot{} h_2 \in H\)</span>. For example, translation transformations are a subgroup because you cannot accidentally create a rotation when combining two translations.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>This process of constructing cosets and then using that to lift our function is closely related to the process of finding an induced representation on <span class="math notranslate nohighlight">\(G\)</span> via a representation on <span class="math notranslate nohighlight">\(H\)</span>.</p>
</aside>
<p>After constructing a subgroup <span class="math notranslate nohighlight">\(H\)</span>, we can apply an element <span class="math notranslate nohighlight">\(g\)</span> to every element in <span class="math notranslate nohighlight">\(H\)</span>, written as</p>
<div class="amsmath math notranslate nohighlight" id="equation-51355af6-4f19-41f7-84b0-ee8d3e58027c">
<span class="eqno">(10.7)<a class="headerlink" href="#equation-51355af6-4f19-41f7-84b0-ee8d3e58027c" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}
gH = \left\{g \cdot h \forall h \in H\right\}
\end{equation}\]</div>
<p>If this sounds strange, wait for an example. <span class="math notranslate nohighlight">\(gH\)</span> is called a <strong>left coset</strong>. We mention the direction because <span class="math notranslate nohighlight">\(G\)</span>‚Äôs binary operation may not be commutative (non-abelian). What happens if <span class="math notranslate nohighlight">\(g\)</span> is in <span class="math notranslate nohighlight">\(H\)</span>? No problem; <span class="math notranslate nohighlight">\(H\)</span> is a group so applying an element to every element in <span class="math notranslate nohighlight">\(H\)</span> just gives back <span class="math notranslate nohighlight">\(H\)</span> (i.e. <span class="math notranslate nohighlight">\(hH = H\)</span>). Cosets are not groups, they are definitely not closed or have inverses. What‚Äôs the point of making all these cosets? Remember our goal is to partition <span class="math notranslate nohighlight">\(G\)</span> into a bunch of smaller sets so that we have one for each point in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. Constructing cosets partitions <span class="math notranslate nohighlight">\(G\)</span> for sure, but do we get enough? Could we accidentally have overlaps between cosets, where <span class="math notranslate nohighlight">\(g_1H\)</span> and <span class="math notranslate nohighlight">\(g_2H\)</span> contain the same elements?</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>If your group involves rotations, make life easy on yourself and always choose <span class="math notranslate nohighlight">\(x_0\)</span> as the origin (or center of the rotations).</p>
</aside>
<p>It turns out if our space is homogeneous we can construct our cosets in a special way so that we have exactly one coset for each point in the space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. To get our group, we pick an arbitrary point in the space <span class="math notranslate nohighlight">\(x_0\)</span>. Often this will be the origin. Then we choose our subgroup <span class="math notranslate nohighlight">\(H\)</span> to be all group elements that leave <span class="math notranslate nohighlight">\(x_0\)</span> unchanged.  This is called a stabilizer subgroup <span class="math notranslate nohighlight">\(H_0\)</span> and is defined as</p>
<div class="amsmath math notranslate nohighlight" id="equation-f33b37a8-ee9b-4c38-b40c-7652382f4ca0">
<span class="eqno">(10.8)<a class="headerlink" href="#equation-f33b37a8-ee9b-4c38-b40c-7652382f4ca0" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}
H_0 = \left\{ g \in G \,\textrm{such that}\, g x_0 = x_0\right\}
\end{equation}\]</div>
<p>We will not prove that this is a group itself. This defines our subgroup. Here‚Äôs the remarkable thing: we will have exactly enough cosets with this stabilizer as there are points in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. However, multiple <span class="math notranslate nohighlight">\(g\)</span>s will give the same coset (as expected, since <span class="math notranslate nohighlight">\(|G| &gt; |\mathcal{X}|\)</span>).</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>This set of all cosets is itself a group and it is written as <span class="math notranslate nohighlight">\(G / H_0\)</span>. The fact that the cosets is a group is just weird. What is the identity coset? How do you define binary operations on cosets? It turns out we do not need these items but it is fascinating.</p>
</aside>
<p>Now comes the details, how do we match-up points in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> to the cosets? We know that the space is homogeneous  so each point in <span class="math notranslate nohighlight">\(x\)</span> can be reached from our arbitrary origin by a group element <span class="math notranslate nohighlight">\(gx_0 = x\)</span>. That‚Äôs one way to connect points to group elements, but which coset will <span class="math notranslate nohighlight">\(g\)</span> be in? There also may be multiple <span class="math notranslate nohighlight">\(g\)</span>s that satisfy the equation. It turns out that all the group elements that satisfy the equation will be in the same coset. The reason why is that <span class="math notranslate nohighlight">\(g\cdot h x_0 = gx_0\)</span> because all elements <span class="math notranslate nohighlight">\(h\)</span> of the stabilizer group do not move <span class="math notranslate nohighlight">\(x_0\)</span>. Quite elegant.</p>
<p>How do we find which coset we need? Since the identity <span class="math notranslate nohighlight">\(e\)</span> is in <span class="math notranslate nohighlight">\(H_0\)</span> (by definition), the coset <span class="math notranslate nohighlight">\(gH_0\)</span> will contain <span class="math notranslate nohighlight">\(g\)</span> itself. Thus, we can convert a function <span class="math notranslate nohighlight">\(f(x)\)</span> from the space to be a function on the quotient space <span class="math notranslate nohighlight">\(f(g)\)</span> via what we call <strong>lifting</strong>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-8ee307e1-b08a-43ae-aa89-594b15f4ebec">
<span class="eqno">(10.9)<a class="headerlink" href="#equation-8ee307e1-b08a-43ae-aa89-594b15f4ebec" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}
f\uparrow^G(g) = f(gx_0)
\end{equation}\]</div>
<p>All that discussion and thinking for such a simple equation. One point to note is that you can plug any element <span class="math notranslate nohighlight">\(g\)</span> from the group into <span class="math notranslate nohighlight">\(f\uparrow^G(g)\)</span> but it is bijective only over <span class="math notranslate nohighlight">\(G / H\)</span> (the cosets). Your null space will be the whole subgroup <span class="math notranslate nohighlight">\(H_0\)</span>.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>A coset can have multiple labels in this system. <span class="math notranslate nohighlight">\(g_1H_0\)</span> and <span class="math notranslate nohighlight">\(g_2H_0\)</span> could be the same coset. There are no consequences of this, but just be aware.</p>
</aside>
<p>Going the opposite, from a function on the group to the space, is called <strong>projecting</strong> because it will have a smaller domain. We can use the same process as above. We create the quotient space and then just take the average over a single coset to get a single value for the point <span class="math notranslate nohighlight">\(x\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-3133cccb-17c7-4794-9fe1-5778baadb76d">
<span class="eqno">(10.10)<a class="headerlink" href="#equation-3133cccb-17c7-4794-9fe1-5778baadb76d" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}
f\downarrow_\mathcal{X}(x) = \frac{1}{|H_0|}\sum_{u \in gH_0} f(u), \: gx_0 = x
\end{equation}\]</div>
<p>where we‚Äôve used the fact that <span class="math notranslate nohighlight">\(|gH_0| = |H_0|\)</span>. Note that the coset generating element <span class="math notranslate nohighlight">\(g\)</span> is found by solving <span class="math notranslate nohighlight">\(gx_0 = x\)</span>, where of course <span class="math notranslate nohighlight">\(g\)</span> is not a stabilizing element (otherwise <span class="math notranslate nohighlight">\(gx_0 = x_0\)</span> by definition). Let‚Äôs see some examples now to make all of these easier to understand.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="c80afe37-b523-4dff-8862-43b79552adee" name="b156a3f6-7bfe-488a-8e16-02d74330d830" type="radio">
</input><label class="tabbed-label" for="c80afe37-b523-4dff-8862-43b79552adee">
‚¨° Finite Group <span class="math notranslate nohighlight">\(Z_6\)</span> </label><div class="tabbed-content docutils">
<p>Our function is the color of the vertices in our picture <span class="pasted-inline"><img alt="../_images/Equivariant_84_0.png" src="../_images/Equivariant_84_0.png" /></span> <span class="math notranslate nohighlight">\(f(x) = (r, g, b)\)</span> where <span class="math notranslate nohighlight">\(r,g,b\)</span> are fractions of the color red, blue green. If we define the vertices to start at the line pointing up, we can label them <span class="math notranslate nohighlight">\(0,\ldots,5\)</span>. So for example <span class="math notranslate nohighlight">\(f(0) =(0.11, 0.74, 0.61)\)</span>, which is the color of the top vertex.</p>
<p>We can define the origin as <span class="math notranslate nohighlight">\(x_0 = 0\)</span>. <span class="math notranslate nohighlight">\(|G| = |\mathcal{X}|\)</span> for this finite group and thus our stabilizer subgroup only contains the identity <span class="math notranslate nohighlight">\(H_0 = \{e\}\)</span>. Our cosets and their associated points will be <span class="math notranslate nohighlight">\((eH_0, x = 0), (rH_0, x = 1), (r^2H_0, x = 2), (r^3H_0, x = 3), (r^4H_0, x = 4), (r^5H_0, x = 5)\)</span>. The lifted <span class="math notranslate nohighlight">\(f\uparrow^G(g)\)</span> can be easily defined using these cosets.</p>
</div>
<input id="812a18ee-ddf4-4dbf-87f7-5aabe321006e" name="b156a3f6-7bfe-488a-8e16-02d74330d830" type="radio">
</input><label class="tabbed-label" for="812a18ee-ddf4-4dbf-87f7-5aabe321006e">
‚ñ© Locally Compact p4m</label><div class="tabbed-content docutils">
<p>p4m is intended for images, so our example will be a function <span class="math notranslate nohighlight">\(f: \mathbb{R}^2 \rightarrow \mathbb{R}^3\)</span> that represents a color image. This group contains rotations about the origin, so if we choose the origin as our stabilizer it will cleanly separate our group. Namely:</p>
<div class="math notranslate nohighlight">
\[
H_0 = \left\{e_ne_r, e_nr, e_nr^2, e_nr^3 , e_ns , e_nrs , e_nr^2s , e_nr^3s\right\}
\]</div>
<p>where our elements have been written out as the semidirect product of translations and <span class="math notranslate nohighlight">\(D_4\)</span> as discussed previously. Let‚Äôs compute a coset to get a sense of this process. Consider the group element <span class="math notranslate nohighlight">\(t_{1,0}e_r\)</span> creating the coset <span class="math notranslate nohighlight">\(t_{1,0}e_rH_0\)</span>. The first element of the coset is <span class="math notranslate nohighlight">\(t_{1,0}e_r \cdot e_ne_r = t_{1,0}e_r\)</span>. The second element is <span class="math notranslate nohighlight">\(t_{1,0}e_r \cdot t_{0,0}r = t_{1,0}r\)</span>. The rest of the elements of this coset are:</p>
<div class="math notranslate nohighlight">
\[
t_{1,0}e_rH_0 = \left\{t_{1,0}e_r , t_{1,0}r , t_{1,0}r^2 ,t_{1,0}r^3 , t_{1,0}s , t_{1,0}rs , t_{1,0}r^2s , t_{1,0}r^3s\right\}
\]</div>
<p>Note these were simple to compute because <span class="math notranslate nohighlight">\(\phi(g)(e_n) = ge_ng^{-1} = e_n\)</span>. Now what point is this associated with? Consider the first non-identity coset element <span class="math notranslate nohighlight">\(t_{1,0}r\)</span> acting on the origin: <span class="math notranslate nohighlight">\((0,0)\rightarrow(0,0)\rightarrow(1,0)\)</span>. You‚Äôll see similarly that all elements in the coset will follow the same pattern: the first element from <span class="math notranslate nohighlight">\(H_0\)</span> doesn‚Äôt move the origin (by definition) and the second element is the same in the coset (translation by <span class="math notranslate nohighlight">\(x + 1\)</span>). Thus, the first coset <span class="math notranslate nohighlight">\(t_{1,0}e_rH_0\)</span> is associated with the point <span class="math notranslate nohighlight">\((1,0)\)</span>.</p>
<p>Now consider a coset that involves a <span class="math notranslate nohighlight">\(D_4\)</span> element: <span class="math notranslate nohighlight">\(t_{1,0}rsH_0\)</span>. You can compute its elements as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
t_{1,0}rsH_0 = \left\{t_{1,0}rs, t_{1,0}s, t_{1,0}r^3s, t_{1,0}r^2s, t_{1,0}r, t_{1,0}e_r , t_{1,0}r^3 , t_{1,0}r^2\\\right\}
\end{split}\]</div>
<p>This contains all the same elements as the coset <span class="math notranslate nohighlight">\(t_{1,0}e_rH_0\)</span>! This is because we have more group elements than space in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>; multiple <span class="math notranslate nohighlight">\(g\)</span>‚Äôs result in the same coset. This doesn‚Äôt change our intuition though: the translation transform still defines the connection between our coset and the space. Our lifting function will be</p>
<div class="math notranslate nohighlight">
\[
f\uparrow^G(g) = f\uparrow^G\left((t_{x,y}, h)\right) = f(x,y)
\]</div>
</div>
<input id="13ebfa85-d50d-4db2-92b6-5ad72e72eeb1" name="b156a3f6-7bfe-488a-8e16-02d74330d830" type="radio">
</input><label class="tabbed-label" for="13ebfa85-d50d-4db2-92b6-5ad72e72eeb1">
‚öΩ SO(3) Lie Group</label><div class="tabbed-content docutils">
<p>For this example, our function will be points on the sphere <span class="math notranslate nohighlight">\(f(x) = \sum_i \delta(x - x_i)\)</span>. We can represent the group element rotations (among other choices) as being the product of three rotations about the <span class="math notranslate nohighlight">\(y\)</span> and <span class="math notranslate nohighlight">\(z\)</span> axes: <span class="math notranslate nohighlight">\(R_z(\alpha)R_y(\beta)R_z(\gamma)\)</span> If that seems surprising, remember that rotations are not commutative. Santa lives in the north pole, so let‚Äôs choose the north pole <span class="math notranslate nohighlight">\((0, 0, 1)\)</span> as our stabilizer. You cannot choose <span class="math notranslate nohighlight">\((0,0,0)\)</span> remember because it is not in the space. Our subgroup is rotations that only involve <span class="math notranslate nohighlight">\(\gamma\)</span>, for example <span class="math notranslate nohighlight">\(R_z(0)R_y(0)R_z(90)\)</span> is in our subgroup <span class="math notranslate nohighlight">\(H_0\)</span>. Let‚Äôs generate a coset, say for the group element <span class="math notranslate nohighlight">\(g = R_z(120)R_y(0)R_z(60)\)</span>. The coset <span class="math notranslate nohighlight">\(gH_0\)</span> will be rotations of <span class="math notranslate nohighlight">\(R_z(120)R_y(0)R_z(60)R_z(0)R_y(0)R_z(\gamma)\)</span>, which can be simplified to <span class="math notranslate nohighlight">\(R_z(120)R_y(0)R_z(60 + \gamma)\)</span>. Thus the coset is <span class="math notranslate nohighlight">\(gH_0 = \left\{R_z(120)R_y(0)R_z(60 + \gamma)\, \forall \gamma \in [0, 2\pi]\right\}\)</span></p>
<p>Now what point is associated with this coset? It will be this rotation applied to the origin: <span class="math notranslate nohighlight">\(R_z(120)R_y(0)R_z(60 + \gamma)x_0\)</span>. The first rotation has no effect, by definition, so it becomes <span class="math notranslate nohighlight">\(R_z(120)R_y(0)x_0\)</span>. The general form is that the coset for a point <span class="math notranslate nohighlight">\(x\)</span> is the rotation such that <span class="math notranslate nohighlight">\(R_z(\alpha)R_y(\beta)x_0 = x\)</span>. This quotient space happens to be identical to SO(2), rotations in 2D, because it‚Äôs defined by two angles. The lifting functions is defined as:</p>
<div class="math notranslate nohighlight">
\[
f\uparrow^G(g) = f\uparrow^G\left(R_z(\alpha)R_y(\beta)R_z(\gamma)\right) = f\left(R_z(\alpha)R_y(\beta)x_0\right)
\]</div>
</div>
</div>
</section>
<section id="g-equivariant-convolutions-on-finite-groups">
<h2><span class="section-number">10.7. </span>G-Equivariant Convolutions on Finite Groups<a class="headerlink" href="#g-equivariant-convolutions-on-finite-groups" title="Permalink to this headline">¬∂</a></h2>
<p>We now have all the tools to build an equivariant network for a finite group. We‚Äôll continue with our example group <span class="math notranslate nohighlight">\(Z_6\)</span> on vertices of a hexagon. The cells below does our imports.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">dmol</span>
<span class="kn">from</span> <span class="nn">dmol</span> <span class="kn">import</span> <span class="n">color_cycle</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs start by defining our input function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># make our colors (nothing to do with the model)</span>

<span class="n">vertex_colors</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">color_cycle</span><span class="p">:</span>
    <span class="n">hex_color</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="mi">16</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">hex_color</span> <span class="o">//</span> <span class="mi">256</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">hex_color</span> <span class="o">=</span> <span class="n">hex_color</span> <span class="o">-</span> <span class="n">r</span> <span class="o">*</span> <span class="mi">256</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">hex_color</span> <span class="o">//</span> <span class="mi">256</span>
    <span class="n">hex_color</span> <span class="o">=</span> <span class="n">hex_color</span> <span class="o">-</span> <span class="n">g</span> <span class="o">*</span> <span class="mi">256</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">hex_color</span>
    <span class="n">vertex_colors</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">r</span> <span class="o">/</span> <span class="mi">256</span><span class="p">,</span> <span class="n">g</span> <span class="o">/</span> <span class="mi">256</span><span class="p">,</span> <span class="n">b</span> <span class="o">/</span> <span class="mi">256</span><span class="p">))</span>
<span class="n">vertex_colors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vertex_colors</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">z6_fxn</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">vertex_colors</span><span class="p">[</span><span class="n">x</span><span class="p">]</span>


<span class="n">z6_fxn</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.265625, 0.265625, 0.265625])
</pre></div>
</div>
</div>
</div>
<p>If we assume our group is indexed already by our vertex coordinates <span class="math notranslate nohighlight">\(\{0,\ldots, 5\}\)</span> then our function is already defined on the group. Now we need our trainable kernel function. It will be defined like our other function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># make weights be 3x3 matrices at each group element</span>
<span class="c1"># 3x3 so that we have 3 color channels in and 3 out</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">z6_omega</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">weights</span><span class="p">[</span><span class="n">x</span><span class="p">]</span>


<span class="n">z6_omega</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[-0.18718385,  1.53277921,  1.46935877],
       [ 0.15494743,  0.37816252, -0.88778575],
       [-1.98079647, -0.34791215,  0.15634897]])
</pre></div>
</div>
</div>
</div>
<p>Now we can define our group convolution operator from Equation 8.6. We do need one helper function to get an inverse group element. Remember too that this returns a <em>function</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">z6_inv</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">6</span> <span class="o">-</span> <span class="n">g</span><span class="p">)</span> <span class="o">%</span> <span class="mi">6</span>


<span class="k">def</span> <span class="nf">z6_prod</span><span class="p">(</span><span class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">g1</span> <span class="o">+</span> <span class="n">g2</span><span class="p">)</span> <span class="o">%</span> <span class="mi">6</span>


<span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">out</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
        <span class="c1"># einsum is so we can do matrix product for elements of f and g,</span>
        <span class="c1"># since we have one matrix per color</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ij,ijk-&gt;ik&quot;</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">z6_prod</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">z6_inv</span><span class="p">(</span><span class="n">g</span><span class="p">))),</span> <span class="n">p</span><span class="p">(</span><span class="n">g</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">c</span>

    <span class="k">return</span> <span class="n">out</span>


<span class="n">conv</span><span class="p">(</span><span class="n">z6_fxn</span><span class="p">,</span> <span class="n">z6_omega</span><span class="p">)(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 1.5752359 ,  3.70837565, -3.68896212])
</pre></div>
</div>
</div>
</div>
<p>At this point, we can now verify that the CNN is equivariant by comparing transforming the input function and the output function. We‚Äôll need to define our function transforms as well.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">z6_fxn_trans</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>
    <span class="k">return</span> <span class="k">lambda</span> <span class="n">h</span><span class="p">:</span> <span class="n">f</span><span class="p">(</span><span class="n">z6_prod</span><span class="p">(</span><span class="n">z6_inv</span><span class="p">(</span><span class="n">g</span><span class="p">),</span> <span class="n">h</span><span class="p">))</span>


<span class="n">z6_fxn</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">z6_fxn_trans</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">z6_fxn</span><span class="p">)(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([0.265625, 0.265625, 0.265625]),
 array([0.94921875, 0.70703125, 0.3828125 ]))
</pre></div>
</div>
</div>
</div>
<p>First we‚Äôll compute <span class="math notranslate nohighlight">\(\psi\left[\mathbb{T}_2 f(x)\right]\)</span> ‚Äì the network acting on the transformed input function</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trans_element</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">trans_input_fxn</span> <span class="o">=</span> <span class="n">z6_fxn_trans</span><span class="p">(</span><span class="n">trans_element</span><span class="p">,</span> <span class="n">z6_fxn</span><span class="p">)</span>
<span class="n">trans_input_out</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">trans_input_fxn</span><span class="p">,</span> <span class="n">z6_omega</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we compute <span class="math notranslate nohighlight">\(\mathbb{T}_2\psi\left[f(x)\right]\)</span> ‚Äì the transform acting on the network output</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output_fxn</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">z6_fxn</span><span class="p">,</span> <span class="n">z6_omega</span><span class="p">)</span>
<span class="n">trans_output_out</span> <span class="o">=</span> <span class="n">z6_fxn_trans</span><span class="p">(</span><span class="n">trans_element</span><span class="p">,</span> <span class="n">output_fxn</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;g -&gt; psi[f(g)], g -&gt; psi[Tgf(g)], g-&gt; Tg psi[f(g)]&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="n">i</span><span class="p">,</span>
        <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">z6_fxn</span><span class="p">,</span> <span class="n">z6_omega</span><span class="p">)(</span><span class="n">i</span><span class="p">),</span> <span class="mi">2</span><span class="p">),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">trans_input_out</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="mi">2</span><span class="p">),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">trans_output_out</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="mi">2</span><span class="p">),</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>g -&gt; psi[f(g)], g -&gt; psi[Tgf(g)], g-&gt; Tg psi[f(g)]
0 [ 1.58  3.71 -3.69] [ 4.16  0.82 -2.78] [ 4.16  0.82 -2.78]
1 [ 4.06  2.55 -3.2 ] [ 2.9   2.33 -2.6 ] [ 2.9   2.33 -2.6 ]
2 [ 2.59  2.34 -1.97] [ 1.58  3.71 -3.69] [ 1.58  3.71 -3.69]
3 [ 2.66  2.25 -1.13] [ 4.06  2.55 -3.2 ] [ 4.06  2.55 -3.2 ]
4 [ 4.16  0.82 -2.78] [ 2.59  2.34 -1.97] [ 2.59  2.34 -1.97]
5 [ 2.9   2.33 -2.6 ] [ 2.66  2.25 -1.13] [ 2.66  2.25 -1.13]
</pre></div>
</div>
</div>
</div>
<p>We can see that the outputs indeed match and therefore our network is G-equivariant. One last detail is that it would be nice to visualize this, so we can add a nonlinearity to remap our output back to color space. Our colors should be between 0 and 1, so we can use a sigmoid to put the activations back to valid colors. I‚Äôll hide the input since it contains irrelevant code, but here is the visualization of the previous numbers showing the equivariance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">c1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">z6_fxn</span><span class="p">,</span> <span class="n">z6_omega</span><span class="p">)</span>
<span class="n">c2</span> <span class="o">=</span> <span class="n">trans_input_out</span>
<span class="n">c3</span> <span class="o">=</span> <span class="n">trans_output_out</span>
<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sa">r</span><span class="s2">&quot;$\psi\left[f(g)\right]$&quot;</span><span class="p">,</span>
    <span class="sa">r</span><span class="s2">&quot;$\psi\left[\mathbb</span><span class="si">{T}</span><span class="s2">_2f(g)\right]$&quot;</span><span class="p">,</span>
    <span class="sa">r</span><span class="s2">&quot;$\mathbb</span><span class="si">{T}</span><span class="s2">_2\psi\left[f(g)\right]$&quot;</span><span class="p">,</span>
<span class="p">]</span>


<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">convert_color</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="o">*</span> <span class="mi">256</span><span class="o">**</span><span class="mi">3</span> <span class="o">+</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">g</span><span class="p">)</span> <span class="o">*</span> <span class="mi">256</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">*</span> <span class="mi">256</span><span class="p">)</span>
    <span class="k">return</span> <span class="s2">&quot;#</span><span class="si">{:6X}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>


<span class="n">c1</span> <span class="o">=</span> <span class="p">[</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">c1</span><span class="p">(</span><span class="n">i</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)]</span>
<span class="n">c2</span> <span class="o">=</span> <span class="p">[</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">c2</span><span class="p">(</span><span class="n">i</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)]</span>
<span class="n">c3</span> <span class="o">=</span> <span class="p">[</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">c3</span><span class="p">(</span><span class="n">i</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">squeeze</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">),</span>
        <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">points</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">points</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
    <span class="c1"># plt.plot([0, points[0,0]], [0, points[0, 1]], color=&#39;black&#39;, zorder=0)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.4</span><span class="p">,</span> <span class="mf">1.4</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.4</span><span class="p">,</span> <span class="mf">1.4</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">titles</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Equivariant_24_0.png" src="../_images/Equivariant_24_0.png" />
</div>
</div>
<p>As you can see, our output looks the same if we apply the rotation either before or after, so our network is G-equivariant.</p>
</section>
<section id="g-equivariant-convolutions-with-translation">
<h2><span class="section-number">10.8. </span>G-Equivariant Convolutions with Translation<a class="headerlink" href="#g-equivariant-convolutions-with-translation" title="Permalink to this headline">¬∂</a></h2>
<p>How can we treat the p4m group? We cannot directly use the continuous convolution definition because the rotations/mirror subgroup is finite and we cannot use the finite convolution because the translation subgroup is locally compact (infinitely many elements). Instead, we will exploit the structure of the group: it is constructed via a semidirect product so each group element is a pair of elements. Namely we can rewrite Equation 8.6 using the constituent subgroups <span class="math notranslate nohighlight">\(N \rtimes H\)</span> and writing elements <span class="math notranslate nohighlight">\(g = hn, g^{-1} = n^{-1}h^{-1}\)</span>.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Remember that <span class="math notranslate nohighlight">\(g = nh\)</span> is fine to use because <span class="math notranslate nohighlight">\((n, e_r)\cdot (e_n, h) = (n, h)\)</span>, whereas the reverse requires using the conjugation <span class="math notranslate nohighlight">\(\phi(h)(n)\)</span>.</p>
</aside>
<div class="amsmath math notranslate nohighlight" id="equation-5d793fa9-5776-4881-8a6a-84a329b559de">
<span class="eqno">(10.11)<a class="headerlink" href="#equation-5d793fa9-5776-4881-8a6a-84a329b559de" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}
(f * \omega)(u) = \sum_{n \in N}\sum_{h \in H} f\uparrow^G\left(un^{-1}h^{-1}\right)\omega(hn)
\end{equation}\]</div>
<p>Now we must treat the fact that there are an infinite number of elements in <span class="math notranslate nohighlight">\(N\)</span> (the translations). We can simply choose the kernel function (<span class="math notranslate nohighlight">\(\omega\)</span>) to only have support (<span class="math notranslate nohighlight">\(\omega(g) &gt; 0\)</span>) at locations we want and that will simplify the integration. This may seem ad-hoc ‚Äì but remember we already made choices like not including 45¬∞ rotations. There do exist ways to systematically treat how to narrow the kernels into ‚Äúneigbhorhoods‚Äù of groups in <span id="id9">[<a class="reference internal" href="#id107" title="Marc Finzi, Samuel Stanton, Pavel Izmailov, and Andrew Gordon Wilson. Generalizing convolutional neural networks for equivariance to lie groups on arbitrary continuous data. arXiv preprint arXiv:2002.12880, 2020.">FSIW20</a>]</span> or you can find a rigorous derivation specifically for p4 in <span id="id10">[<a class="reference internal" href="#id108" title="David W Romero, Erik J Bekkers, Jakub M Tomczak, and Mark Hoogendoorn. Attentive group equivariant convolutional networks. arXiv, pages arXiv‚Äì2002, 2020.">RBTH20</a>]</span> or <span id="id11">[<a class="reference internal" href="#id109" title="Taco Cohen and Max Welling. Group equivariant convolutional networks. In International conference on machine learning, 2990‚Äì2999. 2016.">CW16</a>]</span>.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>I have a hidden cell below which does a bit of magic. It makes the group elements be hashable. That in turn allows me to cache functions, enabling much faster speeds. This code would be unusable otherwise due to all the nested loops.</p>
</aside>
<p>Our goal for the p4m group is image data, so we‚Äôll limit the support of the kernel to only integer translations (like pixels) and limit the distance to 5 units. This simply reduces our sum over the normal subgroup (<span class="math notranslate nohighlight">\(N\)</span>). We can now begin our implementation. We‚Äôll start by loading an image which will serve as our function. It is a <span class="math notranslate nohighlight">\(32\times32\)</span> RGB image. Remember that we need to allow points to have 3 dimensions, where the third dimension is always 1 to accommodate our augmented space.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># From https://gist.github.com/Susensio/61f4fee01150caaac1e10fc5f005eb75</span>

<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">lru_cache</span><span class="p">,</span> <span class="n">wraps</span>


<span class="k">def</span> <span class="nf">np_cache</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;LRU cache implementation for functions whose FIRST parameter is a numpy array</span>
<span class="sd">    &gt;&gt;&gt; array = np.array([[1, 2, 3], [4, 5, 6]])</span>
<span class="sd">    &gt;&gt;&gt; @np_cache(maxsize=256)</span>
<span class="sd">    ... def multiply(array, factor):</span>
<span class="sd">    ...     print(&quot;Calculating...&quot;)</span>
<span class="sd">    ...     return factor*array</span>
<span class="sd">    &gt;&gt;&gt; multiply(array, 2)</span>
<span class="sd">    Calculating...</span>
<span class="sd">    array([[ 2,  4,  6],</span>
<span class="sd">           [ 8, 10, 12]])</span>
<span class="sd">    &gt;&gt;&gt; multiply(array, 2)</span>
<span class="sd">    array([[ 2,  4,  6],</span>
<span class="sd">           [ 8, 10, 12]])</span>
<span class="sd">    &gt;&gt;&gt; multiply.cache_info()</span>
<span class="sd">    CacheInfo(hits=1, misses=1, maxsize=256, currsize=1)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">decorator</span><span class="p">(</span><span class="n">function</span><span class="p">):</span>
        <span class="nd">@wraps</span><span class="p">(</span><span class="n">function</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="n">np_array</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="n">hashable_array</span> <span class="o">=</span> <span class="n">array_to_tuple</span><span class="p">(</span><span class="n">np_array</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">cached_wrapper</span><span class="p">(</span><span class="n">hashable_array</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="nd">@lru_cache</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">cached_wrapper</span><span class="p">(</span><span class="n">hashable_array</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="n">array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">hashable_array</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">function</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">array_to_tuple</span><span class="p">(</span><span class="n">np_array</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Iterates recursivelly.&quot;&quot;&quot;</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">array_to_tuple</span><span class="p">(</span><span class="n">_</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">np_array</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np_array</span>

        <span class="c1"># copy lru_cache attributes over too</span>
        <span class="n">wrapper</span><span class="o">.</span><span class="n">cache_info</span> <span class="o">=</span> <span class="n">cached_wrapper</span><span class="o">.</span><span class="n">cache_info</span>
        <span class="n">wrapper</span><span class="o">.</span><span class="n">cache_clear</span> <span class="o">=</span> <span class="n">cached_wrapper</span><span class="o">.</span><span class="n">cache_clear</span>

        <span class="k">return</span> <span class="n">wrapper</span>

    <span class="k">return</span> <span class="n">decorator</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load image and drop alpha channel</span>
<span class="n">W</span> <span class="o">=</span> <span class="mi">32</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">func_vals</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">&quot;quadimg.png&quot;</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]</span>
<span class="k">except</span> <span class="ne">FileNotFoundError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="c1"># maybe on google colab</span>
    <span class="kn">import</span> <span class="nn">urllib.request</span>

    <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span>
        <span class="s2">&quot;https://raw.githubusercontent.com/whitead/dmol-book/master/dl/quadimg.png&quot;</span><span class="p">,</span>
        <span class="s2">&quot;quadimg.png&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">func_vals</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">&quot;quadimg.png&quot;</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]</span>
<span class="c1"># we pad it with zeros to show boundary</span>
<span class="n">func_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
    <span class="n">func_vals</span><span class="p">,</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=</span><span class="mf">0.2</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">pix_func</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c1"># clip &amp; squeeze &amp; round to account for transformed values</span>
    <span class="n">xclip</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="o">-</span><span class="n">W</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="c1"># points are centered, fix that</span>
    <span class="n">xclip</span> <span class="o">+=</span> <span class="p">[</span><span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="c1"># add 1 to account for padding</span>
    <span class="k">return</span> <span class="n">func_vals</span><span class="p">[</span><span class="n">xclip</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">xclip</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_func</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">gridx</span><span class="p">,</span> <span class="n">gridy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">indexing</span><span class="o">=</span><span class="s2">&quot;ij&quot;</span>
    <span class="p">)</span>
    <span class="c1"># make it into batched x,y indices and add dummy 1 indices for augmented space</span>
    <span class="n">batched_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span>
        <span class="p">(</span><span class="n">gridx</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">gridy</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">gridx</span><span class="o">.</span><span class="n">flatten</span><span class="p">()))</span>
    <span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">batched_idx</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;upper&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>


<span class="n">plot_func</span><span class="p">(</span><span class="n">pix_func</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Equivariant_29_0.png" src="../_images/Equivariant_29_0.png" />
</div>
</div>
<p>Now let‚Äôs define our G-function transform so that we can transform our function with group elements. We‚Äôll apply a <span class="math notranslate nohighlight">\(rst_{12,-8}\)</span> element to our function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_h</span><span class="p">(</span><span class="n">rot</span><span class="p">,</span> <span class="n">mirror</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make h subgroup element&quot;&quot;&quot;</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mirror</span><span class="p">:</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
        <span class="p">[[</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">rot</span><span class="p">),</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">rot</span><span class="p">),</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">rot</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">rot</span><span class="p">),</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">r</span> <span class="o">@</span> <span class="n">m</span>


<span class="k">def</span> <span class="nf">make_n</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make normal subgroup element&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dx</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dy</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>


<span class="k">def</span> <span class="nf">g_func_trans</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;compute g-function transform&quot;&quot;&quot;</span>

    <span class="nd">@np_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="n">W</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">fxn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">g</span><span class="o">=</span><span class="n">g</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">f</span><span class="p">):</span>
        <span class="n">ginv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">ginv</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">@</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">fxn</span>


<span class="n">g</span> <span class="o">=</span> <span class="n">make_h</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">@</span> <span class="n">make_n</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="o">-</span><span class="mi">8</span><span class="p">)</span>
<span class="n">tfunc</span> <span class="o">=</span> <span class="n">g_func_trans</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">pix_func</span><span class="p">)</span>
<span class="n">plot_func</span><span class="p">(</span><span class="n">tfunc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Equivariant_31_0.png" src="../_images/Equivariant_31_0.png" />
</div>
</div>
<p>Now we need to create our lifting and projecting maps to go from functions over points to functions over group elements. Remember, our lifting function just takes the translation element and makes that point.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># enumeraet stabilizer subgrou (rotation/mirrors)</span>
<span class="n">stabilizer</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">stabilizer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">make_h</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">j</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">lift</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;lift f into group&quot;&quot;&quot;</span>
    <span class="c1"># create new function from original</span>
    <span class="c1"># that is f(gx_0)</span>
    <span class="nd">@np_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="n">W</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">fxn</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">f</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">g</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>

    <span class="k">return</span> <span class="n">fxn</span>


<span class="k">def</span> <span class="nf">project</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;create projected function over space&quot;&quot;&quot;</span>

    <span class="nd">@np_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="n">W</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">fxn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">f</span><span class="p">):</span>
        <span class="c1"># x may be batched so we have to allow it to be N x 3</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">xi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="c1"># find coset gH</span>
            <span class="n">g</span> <span class="o">=</span> <span class="n">make_n</span><span class="p">(</span><span class="n">xi</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xi</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="c1"># loop over coset</span>
            <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">stabilizer</span><span class="p">:</span>
                <span class="n">ghi</span> <span class="o">=</span> <span class="n">g</span> <span class="o">@</span> <span class="n">h</span>
                <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">f</span><span class="p">(</span><span class="n">ghi</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">stabilizer</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">return</span> <span class="n">fxn</span>


<span class="c1"># try them out</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;lifted&quot;</span><span class="p">,</span> <span class="n">lift</span><span class="p">(</span><span class="n">pix_func</span><span class="p">)(</span><span class="n">g</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;projected&quot;</span><span class="p">,</span> <span class="n">project</span><span class="p">(</span><span class="n">lift</span><span class="p">(</span><span class="n">pix_func</span><span class="p">))([</span><span class="mi">12</span><span class="p">,</span> <span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>lifted [0.93333334 0.7176471  0.43137255]
projected [[0.72941178 0.71764708 0.72156864]]
</pre></div>
</div>
</div>
</div>
<p>We now need to create our kernel functions <span class="math notranslate nohighlight">\(\phi\)</span>. Rather than make a function of the group elements, we‚Äôll use indices to represent the different group elements. Remember we need to apply a sigmoid at the end so that we stay in color space.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kernel_width</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># must be odd</span>
<span class="c1"># make some random values for kernel (untrained)</span>
<span class="c1"># kernel is group elements x 3 x 3. The group elements are structured (for simplicity) as a N x 5 x 5</span>
<span class="c1"># the 3 x 3 part is because we have 3 color channels coming in and 3 going out.</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
    <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stabilizer</span><span class="p">),</span> <span class="n">kernel_width</span><span class="p">,</span> <span class="n">kernel_width</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">kernel</span><span class="p">):</span>
    <span class="nd">@np_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="n">W</span><span class="o">**</span><span class="mi">4</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">fxn</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
        <span class="c1"># It is possible to do this without inner for</span>
        <span class="c1"># loops over convolution (use a standard conv),</span>
        <span class="c1"># but we do this for simplicity.</span>
        <span class="n">result</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">hi</span><span class="p">,</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">stabilizer</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">nix</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">kernel_width</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">kernel_width</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">niy</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">kernel_width</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">kernel_width</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="n">result</span> <span class="o">+=</span> <span class="p">(</span>
                        <span class="n">f</span><span class="p">(</span><span class="n">u</span> <span class="o">@</span> <span class="n">make_n</span><span class="p">(</span><span class="o">-</span><span class="n">nix</span><span class="p">,</span> <span class="o">-</span><span class="n">niy</span><span class="p">)</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
                        <span class="o">@</span> <span class="n">kernel</span><span class="p">[</span><span class="n">hi</span><span class="p">,</span> <span class="n">nix</span> <span class="o">+</span> <span class="n">kernel_width</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">niy</span> <span class="o">+</span> <span class="n">kernel_width</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span>
                    <span class="p">)</span>
        <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fxn</span>


<span class="c1"># compute convolution</span>
<span class="n">cout</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">lift</span><span class="p">(</span><span class="n">pix_func</span><span class="p">))</span>
<span class="c1"># try it out an a group element</span>
<span class="n">cout</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.08769476, 0.82036708, 0.99128031])
</pre></div>
</div>
</div>
</div>
<p>At this point our convolution layer has returned a function over all group elements. We can visualize this by viewing each stabilizer element individually across the normal subgroup. This is like plotting each coset with a choice of representative element.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_coset</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;plot a function over group elements on cosets given representative g&quot;&quot;&quot;</span>
    <span class="n">gridx</span><span class="p">,</span> <span class="n">gridy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">indexing</span><span class="o">=</span><span class="s2">&quot;ij&quot;</span>
    <span class="p">)</span>
    <span class="c1"># make it into batched x,y indices and add dummy 1 indices for augmented space</span>
    <span class="n">batched_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span>
        <span class="p">(</span><span class="n">gridx</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">gridy</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">gridx</span><span class="o">.</span><span class="n">flatten</span><span class="p">()))</span>
    <span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">W</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">bi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batched_idx</span><span class="p">):</span>
        <span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">h</span> <span class="o">@</span> <span class="n">make_n</span><span class="p">(</span><span class="n">bi</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bi</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;upper&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>


<span class="c1"># try it with mirror</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">plot_coset</span><span class="p">(</span><span class="n">make_h</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">lift</span><span class="p">(</span><span class="n">pix_func</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Equivariant_37_0.png" src="../_images/Equivariant_37_0.png" />
</div>
</div>
<p>Now we will plot our convolution for each possible coset representative. This code is <em>incredibly</em> inefficient because we have so many loops in plotting and the convolution. This is where the <code class="docutils literal notranslate"><span class="pre">np_cache</span></code> from above helps.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stabilizer_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;$e$&quot;</span><span class="p">,</span> <span class="s2">&quot;$r$&quot;</span><span class="p">,</span> <span class="s2">&quot;$r^2$&quot;</span><span class="p">,</span> <span class="s2">&quot;$r^3$&quot;</span><span class="p">,</span> <span class="s2">&quot;$s$&quot;</span><span class="p">,</span> <span class="s2">&quot;$rs$&quot;</span><span class="p">,</span> <span class="s2">&quot;$r^2s$&quot;</span><span class="p">,</span> <span class="s2">&quot;$r^3s$&quot;</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">stabilizer_names</span><span class="p">,</span> <span class="n">stabilizer</span><span class="p">)):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">plot_coset</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">cout</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Equivariant_39_0.png" src="../_images/Equivariant_39_0.png" />
</div>
</div>
<p>These convolutions are untrained, so it‚Äôs sort of a diffuse random combination of pixels. You can see each piece of the function broken out by stabilizer group element (the rotation/mirroring). We can stack multiple layers of these convolution if we wanted. At the end, we want to get back to our space with the projection.
Let us now show our layers are equivariant by applying a G-function transform to input and output.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">squeeze</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plot_func</span><span class="p">(</span><span class="n">project</span><span class="p">(</span><span class="n">cout</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\psi\left[f(g)\right]$&quot;</span><span class="p">)</span>

<span class="c1"># make a transformation for visualization purposes</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">make_h</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">@</span> <span class="n">make_n</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
<span class="n">tfunc</span> <span class="o">=</span> <span class="n">g_func_trans</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">project</span><span class="p">(</span><span class="n">cout</span><span class="p">))</span>
<span class="n">plot_func</span><span class="p">(</span><span class="n">tfunc</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\mathbb</span><span class="si">{T}</span><span class="s2">\psi\left[f(g)\right]$&quot;</span><span class="p">)</span>

<span class="n">tcout</span> <span class="o">=</span> <span class="n">project</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">lift</span><span class="p">(</span><span class="n">g_func_trans</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">pix_func</span><span class="p">))))</span>

<span class="n">plot_func</span><span class="p">(</span><span class="n">tcout</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\psi\left[\mathbb</span><span class="si">{T}</span><span class="s2">f(g)\right]$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Equivariant_41_0.png" src="../_images/Equivariant_41_0.png" />
</div>
</div>
<p>This shows that the convolution layer is indeed equivariant. Details not covered here are how to do pooling (if desired) and the choice of nonlinearity. You can find more details on this for the p4m group in Cohen et al. <span id="id12">[<a class="reference internal" href="#id109" title="Taco Cohen and Max Welling. Group equivariant convolutional networks. In International conference on machine learning, 2990‚Äì2999. 2016.">CW16</a>]</span>. This implementation is also quite slow! Kondor et al. <span id="id13">[<a class="reference internal" href="#id104" title="Risi Kondor and Shubhendu Trivedi. On the generalization of equivariance and convolution in neural networks to the action of compact groups. In International Conference on Machine Learning, 2747‚Äì2755. 2018.">KT18</a>]</span> show how you can reduce the number of operations by identifying sparsity in the convolutions.</p>
</section>
<section id="group-representation">
<h2><span class="section-number">10.9. </span>Group Representation<a class="headerlink" href="#group-representation" title="Permalink to this headline">¬∂</a></h2>
<p>p4m was an infinite group but we restricted ourselves to a finite subset. Before we can progress to truly infinite locally compact groups, like SO(3), we need to learn how to systematically represent the group element binary operation. You can find a detailed description of representation theory in Serre <span id="id14">[<a class="reference internal" href="#id113" title="Jean-Pierre Serre. Linear representations of finite groups. Volume 42. Springer, 1977.">Ser77</a>]</span> and it is covered in Zee <span id="id15">[<a class="reference internal" href="#id114" title="Anthony Zee. Group theory in a nutshell for physicists. Princeton University Press, 2016.">Zee16</a>]</span>. Thus far, we‚Äôve discussed the group actions ‚Äì how they affect a point. Now we need to describe how to represent them with matrices. This will be a very quick overview of this topic, but representation of groups is a large area with well-established references. There is specifically a great amount of literature about building up these representations, but we‚Äôll try to focus on using them since you generally can look-up the representations for most groups we‚Äôll operate in.</p>
<p>Let us first define a representation on a group:</p>
<div class="admonition-linear-representation-of-a-group admonition">
<p class="admonition-title">Linear Representation of a Group</p>
<p>Let <span class="math notranslate nohighlight">\(G\)</span> be a group on an <span class="math notranslate nohighlight">\(n\)</span>-dimensional vector space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> . A linear representation of <span class="math notranslate nohighlight">\(G\)</span> is a group homomorphism: <span class="math notranslate nohighlight">\(\rho: G \rightarrow GL(m,\mathbb{C})\)</span> where <span class="math notranslate nohighlight">\(GL(m, \mathbb{C})\)</span> is the space of <span class="math notranslate nohighlight">\(m\times m\)</span> square invertible matrices with complex numbers. The representation <span class="math notranslate nohighlight">\(\rho\)</span> should satisfy the following equation</p>
<div class="amsmath math notranslate nohighlight" id="equation-b1d32e9f-215b-43d3-884b-543b12294b03">
<span class="eqno">(10.12)<a class="headerlink" href="#equation-b1d32e9f-215b-43d3-884b-543b12294b03" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}
\label{rep-def}
\rho\left(g_1\cdot g_2\right) = \rho\left(g_1\right) \rho\left(g_2\right)\; \forall\, g_1,g_2 \in G
\end{equation}\]</div>
<p>where the term <span class="math notranslate nohighlight">\(\rho\left(g_1\right) \rho\left(g_2\right)\)</span> is a matrix product.</p>
</div>
<p>There are a few things to note about this definition. First, the representation assigns matrices to group elements in such a way that multiplying matrices gives the same representation as getting the representation of the binary operation (<span class="math notranslate nohighlight">\(\rho\left(g_1\cdot g_2\right)\)</span>). Second, the matrices have to be square and invertible. This follows from the requirement that group elements must have an inverse, so naturally we need invertible matrices. The invertible requirement also means we often need to allow complex numbers. Third, the <strong>degree</strong> of the representation (<span class="math notranslate nohighlight">\(m\)</span>) need not be the same size as the vector space.</p>
<p>There is a big detail missing from this definition. Does this have anything to do with how the group element affect a point? No. Consider that <span class="math notranslate nohighlight">\(\rho(g_i) = 1\)</span> is a valid representation, as in it satisfies the definition. Yet <span class="math notranslate nohighlight">\(1\)</span> is not the correct way to transforms points with group elements. If we go further and say that the representation is <em>injective</em> (one to one), then we must have a unique representation for every group element. That is called a <strong>faithful representation</strong>. This is better, but it turns out there are still multiple faithful representations for a group.</p>
<p>Remember the way a group affects a point is a <strong>group action</strong>, which maps from the direct product of <span class="math notranslate nohighlight">\(G, \mathcal{X}\)</span> (i.e., a tuple like <span class="math notranslate nohighlight">\((g_2, x)\)</span> to <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>). A group action, if it is linear, can also be a representation. Consider that we write the group action <span class="math notranslate nohighlight">\(\pi\)</span> (how a group element affects a point) as <span class="math notranslate nohighlight">\(\pi(g)(x) = x'\)</span>. You can convert this into a square matrix in <span class="math notranslate nohighlight">\(\mathcal{X}\times\mathcal{X}\)</span> by considering how each element of <span class="math notranslate nohighlight">\(x'\)</span> is affected the element in <span class="math notranslate nohighlight">\(x\)</span>. This matrix can be further shown to be in <span class="math notranslate nohighlight">\(GL(m, \mathcal{X})\)</span> and a representation by relying on its linearity. There isn‚Äôt a special word for this, but often groups are defined in terms of these special matrices that both transforms points and are valid representations (e.g., SO(3)). They are then called the <strong>defining representation</strong> or <strong>fundamental representation</strong>.</p>
<p>Let‚Äôs now see group representations on the examples above that are both group actions and representations.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="78b3ec62-64d6-40ed-ae64-b5bdc205e8a1" name="2970476c-461a-46b2-a8ab-dd88ac84e914" type="radio">
</input><label class="tabbed-label" for="78b3ec62-64d6-40ed-ae64-b5bdc205e8a1">
‚¨° Finite Group <span class="math notranslate nohighlight">\(Z_6\)</span> </label><div class="tabbed-content docutils">
<p>Our group action defined above was modular arithmetic, which is not linear and so we cannot use it to construct representation. There are multiple representation for cyclic groups like <span class="math notranslate nohighlight">\(Z_6\)</span>. If you‚Äôre comfortable with complex numbers, you can build circulant matrices of <span class="math notranslate nohighlight">\(6\)</span>th roots of unity. If that confuses you, like it does me, then you can also just view this group like a rotation group. Just like how if you rotate enough times you get back to the beginning, you can also use rotation matrices of <span class="math notranslate nohighlight">\(360 / 6 = 60^{\circ}\)</span>. This requires a 2D vector representation though for the space. With this choice, a representation is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[\begin{array}{lr}
\cos\frac{k2\pi}{6} &amp; -\sin\frac{k2\pi}{6}\\
\sin\frac{k2\pi}{6} &amp; \cos\frac{k2\pi}{6}\\
\end{array}\right],\, k \in \left\{0, 1, 2, 3, 4, 5\right\}
\end{split}\]</div>
<p>Let‚Äôs verify that this is a representation by checking that <span class="math notranslate nohighlight">\(r^2\cdot\,r^4 = e\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[\begin{array}{lr}
\cos\frac{4\pi}{6} &amp; -\sin\frac{4\pi}{6}\\
\sin\frac{4\pi}{6} &amp; \cos\frac{4\pi}{6}\\
\end{array}\right]\left[\begin{array}{lr}
\cos\frac{8\pi}{6} &amp; -\sin\frac{k2\pi}{6}\\
\sin\frac{8\pi}{6} &amp; \cos\frac{8\pi}{6}\\
\end{array}\right] = \left[\begin{array}{lr}
\cos\frac{12\pi}{6} &amp; -\sin\frac{12\pi}{6}\\
\sin\frac{12\pi}{6} &amp; \cos\frac{12\pi}{6}\\
\end{array}\right] = \left[\begin{array}{lr}
1 &amp; 0\\
0 &amp; 1\\
\end{array}\right]
\end{split}\]</div>
<p>You can also verify that this is a group action by repeated application to the point <span class="math notranslate nohighlight">\((1,0)\)</span>, which will rotate around the unit circle.</p>
</div>
<input id="b944a505-e542-473a-8f81-1c4c9dc12109" name="2970476c-461a-46b2-a8ab-dd88ac84e914" type="radio">
</input><label class="tabbed-label" for="b944a505-e542-473a-8f81-1c4c9dc12109">
‚ñ© Locally Compact p4m</label><div class="tabbed-content docutils">
<p>Our group action defined above for the translation elements is not linear. To define a representation, we can use <span class="xref myst"><strong>Affine Matrices</strong></span> which are <span class="math notranslate nohighlight">\(3\times3\)</span> invertible square matrices. That means even though our goal is 2D data, we need to introduce a 3rd dimension: <span class="math notranslate nohighlight">\((x, y, 1)\)</span>. The 3rd dimension is always <span class="math notranslate nohighlight">\(1\)</span> and is called the augmented dimension. To specify a group representation we simply need to multiply an affine matrix for rotation, reflection, and translation (<em>in that order!</em>). These are:</p>
<p>Rotation:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[\begin{array}{lcr}
\cos\frac{k\pi}{4} &amp; -\sin\frac{k\pi}{4} &amp; 0\\
\sin\frac{k\pi}{4} &amp; \cos\frac{k\pi}{4} &amp; 0\\
0 &amp; 0 &amp; 1\\
\end{array}\right] ,\, k \in \left\{0, 1, 2, 3\right\}
\end{split}\]</div>
<p>Reflection:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[\begin{array}{lcr}
1 &amp; 0 &amp; 0\\
0 &amp; -1 &amp; 0\\
0 &amp; 0 &amp; 1\\
\end{array}\right]
\end{split}\]</div>
<p>Translation:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[\begin{array}{lcr}
1 &amp; 0 &amp; \Delta x\\
0 &amp; 1 &amp; \Delta y\\
0 &amp; 0 &amp; 1\\
\end{array}\right]
\end{split}\]</div>
<p>It is a bit more involved to verify this is a group representation, but you can try a few group element products to convince yourself. Do not forget the special homomorphism (conjugate <span class="math notranslate nohighlight">\(\phi(h)(n)\)</span>) for semidirect products when multiplying group element, which ensures the correct behavior if rearrange the order of the matrices.</p>
</div>
<input id="836bff19-bc19-47ff-b4b0-dc692c59fc23" name="2970476c-461a-46b2-a8ab-dd88ac84e914" type="radio">
</input><label class="tabbed-label" for="836bff19-bc19-47ff-b4b0-dc692c59fc23">
‚öΩ SO(3) Group</label><div class="tabbed-content docutils">
<p>A representation of the SO(3) group is just its usual group action: the product of 3 3D rotation matrices <span class="math notranslate nohighlight">\(R_z(\alpha)R_y(\beta)R_z(\gamma)\)</span> where <span class="math notranslate nohighlight">\(\alpha, \gamma \in [0, 2\pi], \beta \in [0, \pi]\)</span> and the matrices are defined above.</p>
</div>
</div>
<section id="unitary-representations">
<h3><span class="section-number">10.9.1. </span>Unitary Representations<a class="headerlink" href="#unitary-representations" title="Permalink to this headline">¬∂</a></h3>
<p>One minor detail is that if we have some representation <span class="math notranslate nohighlight">\(\rho(g_1)\rho(g_2) = \rho(g_1\cdot g_2)\)</span>, then we could make a ‚Äúnew‚Äù representation <span class="math notranslate nohighlight">\(\rho'\)</span> by inserting some invertible matrix <span class="math notranslate nohighlight">\(\mathbf{S}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\rho'(g) = \mathbf{S}^{-1}\rho(g)\mathbf{S}
\]</div>
<p>because</p>
<div class="math notranslate nohighlight">
\[
\rho'(g_1)\rho'(g_2) = \mathbf{S}^{-1}\rho(g_1)\mathbf{S}\mathbf{S}^{-1}\rho(g_2)\mathbf{S}
\]</div>
<div class="math notranslate nohighlight">
\[
= \mathbf{S}^{-1}\rho(g_1)\rho(g_2)\mathbf{S} = \rho'(g_1\cdot g_2)
\]</div>
<p>There is a theorem, the Unitarity Theorem, that says we can always choose an <span class="math notranslate nohighlight">\(\mathbf{S}\)</span> (for finite groups) such that we make our representation <strong>unitary</strong>. Unitary means that <span class="math notranslate nohighlight">\(\rho(g)^{-1} = \rho^{\dagger}(g)\)</span> for any <span class="math notranslate nohighlight">\(g\)</span>. Remember that <span class="math notranslate nohighlight">\(\rho(g)\)</span> is a matrix, so <span class="math notranslate nohighlight">\(\rho^{\dagger}(g)\)</span> is the adjoint (transpose and complex conjugate) of the matrix. Thus, without any loss of generality we can assume all representations we use are unitary or can be trivially converted to unitary.</p>
</section>
<section id="irreducible-representations">
<h3><span class="section-number">10.9.2. </span>Irreducible representations<a class="headerlink" href="#irreducible-representations" title="Permalink to this headline">¬∂</a></h3>
<p>These representations that both describe the group action and how group elements affect on another are typically <strong>reducible</strong>, meaning if you drop the requirement that they also describe group action they can be simplified. The process of reducing representations is again a topic better explored in other references <span id="id16">[<a class="reference internal" href="#id113" title="Jean-Pierre Serre. Linear representations of finite groups. Volume 42. Springer, 1977.">Ser77</a>]</span>, but here I will sketch out the important ideas. The main idea is that we can form decomposable unitary representation matrices that are composed of smaller block matrices and zero blocks. These smaller blocks, <span class="math notranslate nohighlight">\(\rho_i(g)\)</span>, are <em>irreducible</em> ‚Äî they cannot be broken into smaller blocks and zeros</p>
<div class="amsmath math notranslate nohighlight" id="equation-9e59990d-4468-4167-be7c-d899e492a776">
<span class="eqno">(10.13)<a class="headerlink" href="#equation-9e59990d-4468-4167-be7c-d899e492a776" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}
    \rho(g) = \mathbf{S}^{-1} \begin{pmatrix} 
\rho_0(g) &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \rho_1(g) &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \rho_k(g) \\
\end{pmatrix} \mathbf{S}
\end{equation}\]</div>
<p>This block notation is consistent, regardless of <span class="math notranslate nohighlight">\(g\)</span>. That is a strong statement because <span class="math notranslate nohighlight">\(\rho(g_1)\rho(g_2)\)</span> should give back an element in <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> ‚Äî <span class="math notranslate nohighlight">\(\rho(g')\)</span> ‚Äî with the same block structure.  What is interesting about this notation is that each block is then <em>itself</em> a representation. We could just pick <span class="math notranslate nohighlight">\(\rho_0(g)\)</span> as a representation, and if this block structure is true for all <span class="math notranslate nohighlight">\(g\)</span>, then <span class="math notranslate nohighlight">\(\rho_0(g_1)\rho_0(g_2)\)</span> should give back something with non-zero elements only in the rows/columns of the <span class="math notranslate nohighlight">\(\rho_0(g)\)</span> block. We could also combine <span class="math notranslate nohighlight">\(\rho_0(g)\)</span> and <span class="math notranslate nohighlight">\(\rho_1(g)\)</span> or even <span class="math notranslate nohighlight">\(\rho_0(g)\)</span> and <span class="math notranslate nohighlight">\(\rho_2(g)\)</span>. Thus, these irreducible representations (<strong>irreps</strong>) are the pieces that we use to build any other representation. The irreducible representations are all dimension 1 if <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> is abelian, but otherwise irreducible representations are square matrices.</p>
<p>To add some notation, we use <strong>direct sums</strong> to write the bigger unitary representation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-5f97de04-5e13-4289-90c2-e5d6666c075e">
<span class="eqno">(10.14)<a class="headerlink" href="#equation-5f97de04-5e13-4289-90c2-e5d6666c075e" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}
\rho(g) = \mathbf{S}^{-1} \begin{pmatrix} 
\rho_0(g) &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \rho_1(g) &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \rho_k(g) \\
\end{pmatrix} \mathbf{S} = \rho_0(g)\oplus\rho_1(g)\oplus\ldots\oplus\rho_k(g)
\end{equation}\]</div>
<p>and we could just stop the direct sum wherever we would like. The number of irreducible representations is finite for finite groups and  infinite for locally compact groups. These irreducible representations are like orthonormal basis-functions or basis-vectors from Hilbert spaces. From the Peter-Weyl theorem, they specifically can be transformed to create a complete basis-set for integrable (<span class="math notranslate nohighlight">\(L^2\)</span>) functions of the group. ‚ÄúTransformed‚Äù because irreducible representations are representations of <span class="math notranslate nohighlight">\(g\)</span> ( output a matrix), but we need them to output a scalar to be a basis-set for an integrable function.</p>
<p>Where do we get these integrable functions? Recall we can use lifting to move functions of our space to our group and then these irreducible representations enable us to represent the functions as a (direct) sum of coefficients of the irreducible representations. Remember, each individual irreducible representation is itself a valid representation, but they are not all faithful and so you need some of them to uniquely represent all group elements and all of them to represent arbitrary functions over the group. One final note, these irreducible representations have been essentially mapped out for all groups and thus we look them up in table rather than try to construct them.</p>
</section>
</section>
<section id="g-equivariant-convolutions-on-compact-groups">
<h2><span class="section-number">10.10. </span>G-Equivariant Convolutions on Compact Groups<a class="headerlink" href="#g-equivariant-convolutions-on-compact-groups" title="Permalink to this headline">¬∂</a></h2>
<p>Now we can represent functions on groups as a direct sum (list of increasing length vectors) of coefficients on the irreps as</p>
<div class="math notranslate nohighlight" id="equation-fft">
<span class="eqno">(10.15)<a class="headerlink" href="#equation-fft" title="Permalink to this equation">¬∂</a></span>\[
f(g) =  f_0\cdot\rho_0(g)\oplus\vec{f}_1\cdot\rho_1(g)\oplus\ldots\oplus\vec{f}_k\cdot\rho_k(g)
\]</div>
<p>where the direct sum notation <span class="math notranslate nohighlight">\(\oplus\)</span> is just a shorthand that means put all this stuff into a big matrix of increasingly large blocks. The individual <span class="math notranslate nohighlight">\(\vec{f}_i\)</span>s are called <strong>fragments</strong> to distinguish them from the actual irreps (which are functions).</p>
<p>We could even more compactly write this as <span class="math notranslate nohighlight">\(f(g) =  f_0\oplus\vec{f}_1\oplus\ldots\oplus\vec{f}_k\)</span>. We‚Äôd like to revise the G-Equivariant convolution layer equation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-b22b0c41-9f29-474d-a56c-d4e899996309">
<span class="eqno">(10.16)<a class="headerlink" href="#equation-b22b0c41-9f29-474d-a56c-d4e899996309" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}
\psi(f) = (f * \omega)(u) = \int_G f\uparrow^G\left(ug^{-1}\right)\omega\uparrow^G\left(g\right)\,d\mu(g)
\end{equation}\]</div>
<p>to use irreps now. <em>It turns out that the convolutional integral becomes a product of irreps.</em> This is just like how convolutions in Fourier space become products. <span id="id17">[<a class="reference internal" href="#id104" title="Risi Kondor and Shubhendu Trivedi. On the generalization of equivariance and convolution in neural networks to the action of compact groups. In International Conference on Machine Learning, 2747‚Äì2755. 2018.">KT18</a>]</span>. Our expression simplifies to:</p>
<div class="math notranslate nohighlight" id="equation-compact-gequiv">
<span class="eqno">(10.17)<a class="headerlink" href="#equation-compact-gequiv" title="Permalink to this equation">¬∂</a></span>\[
\psi(f) = f_0 w_0\oplus \vec{f}_1 w_1 \oplus\ldots\oplus \vec{f}_k w_k
\]</div>
<p>This result says we just multiply the irreducible representations by weights, but do not mix across irreps. The weights become matrices if we start to allow multiple channels (multiple fragments). An important point then is how we actually can learn if there is no communication between irreps. That‚Äôs where the nonlinearity comes in. It is discussed in more depth below, but the most common nonlinearity is to take a tensor product (all irreps times all irreps) and then reduce that by multiplying the larger rank tensor by a special tensor for the group called Clebsch-Gordan coefficients that reduces it equivariantly back down to the direct sum of irreps. This enables mixing between the irreps and is nonlinear.</p>
<section id="irreducible-representations-on-so-3">
<h3><span class="section-number">10.10.1. </span>Irreducible representations on SO(3)<a class="headerlink" href="#irreducible-representations-on-so-3" title="Permalink to this headline">¬∂</a></h3>
<p>There is an infinite sequence of possible irreducible representations for the SO(3) group known as the Wigner D-matrices. They must be of odd dimension, and so are traditionally written as the sequence <span class="math notranslate nohighlight">\(2l + 1\)</span> where <span class="math notranslate nohighlight">\(l\)</span> is an integer that serves as the irreducible representation index. The Wigner D-matrices are square with dimension <span class="math notranslate nohighlight">\(2l + 1\)</span> and are a function of the group element (e.g., the angles of the rotation). This may be surprising, that the irreducible representations can be of greater dimension than our reducible representation <span class="math notranslate nohighlight">\(R_z(\alpha)R_y(\beta)R_z(\gamma)\)</span>. Of course, remember the matrix blocks we built above ‚Äî we can keep making these representations bigger. But do they have any intuitive meaning? One way to think about irreps larger than the fundamental representation is to consider SO(3) acting on 3 dimensional <span class="math notranslate nohighlight">\(n\)</span>th degree monomials rather than points: <span class="math notranslate nohighlight">\(x^iy^jz^k\)</span> where <span class="math notranslate nohighlight">\(l = i + j + k\)</span>. The trivial representation works on the 0th degree monomial (<span class="math notranslate nohighlight">\(l = 0\)</span>), the <span class="math notranslate nohighlight">\(l = 1\)</span> irrep has three possible monomials (<span class="math notranslate nohighlight">\(x, y, z\)</span>), the <span class="math notranslate nohighlight">\(l=2\)</span> irrep has 5 possible monomials (excluding a redundant term) <span class="math notranslate nohighlight">\(x^2\)</span>, <span class="math notranslate nohighlight">\(y^2\)</span>, <span class="math notranslate nohighlight">\(z^2\)</span>, <span class="math notranslate nohighlight">\(xy\)</span>, $xz. You can find a nice description of <a class="reference external" href="https://math.stackexchange.com/a/40141">this here</a>.</p>
<p>What <span class="math notranslate nohighlight">\(l\)</span> should you choose? It depends on your input and output. If you choose <span class="math notranslate nohighlight">\(l = 0\)</span>, you can only represent scalars (not points/vectors). If you choose <span class="math notranslate nohighlight">\(l = 1\)</span>, you can represent vectors. You can always pick a larger <span class="math notranslate nohighlight">\(l\)</span>, but if you pick a lower <span class="math notranslate nohighlight">\(l\)</span> you will become invariant to the higher-order geometric structure.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>The reason you just plug in the values into the spherical harmonics
is you‚Äôre (1) turning your data into a dirac-delta function and (2) taking its
integral over all the irreps, which turns out to be the same as plugging in the value.</p>
</aside>
<p>Our choice of Euler Angles (zyz rotation) means that the Wigner D-matrices turn into spherical harmonics. Now how do we get our input data, into the irrep for the group SO(3)?  You just plug the input coordinates/features into the spherical harmonics. Have multiple scalar features (e.g., charge, atomic number)? Simply add another axis to the irreps and create multiple ‚Äúchannels‚Äù. Another detail is that our weight size seems to be set by the irrep size. How do we get wider layers (more weights)? The same way: by adding more channels to each irrep.</p>
</section>
<section id="so-3-nonlinearity-mixing">
<h3><span class="section-number">10.10.2. </span>SO(3) Nonlinearity &amp; Mixing<a class="headerlink" href="#so-3-nonlinearity-mixing" title="Permalink to this headline">¬∂</a></h3>
<p>There are two equations for equivariant nonlinearity in SO(3), and they are sometimes combined. The first nonlinearity is a <strong>Clebsch-Gordan tensor product</strong> and enables mixing between irreps. The equation is</p>
<div class="math notranslate nohighlight" id="equation-cg-nl">
<span class="eqno">(10.18)<a class="headerlink" href="#equation-cg-nl" title="Permalink to this equation">¬∂</a></span>\[
\vec{f}_i' = \sum_j\sum_k \mathrm{CG}_{j,k,i} \cdot \vec{f}_j\vec{f}_k 
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathrm{CG}_{j,k,i}\)</span> are the Clebsch-Gordan coefficients that ensure we maintain equivariance after multiplying all irreps with all irreps (and do a change of basis). This expression is sometimes written as <span class="math notranslate nohighlight">\(\mathrm{CG}_{j,k,i}\,\vec{f} \otimes \vec{f}\)</span></p>
<p>As before, <span class="math notranslate nohighlight">\(\vec{f}_i\)</span> are the fragments (coefficients) on the irreps that represent our function <span class="math notranslate nohighlight">\(f(g)\)</span> of the group. The fragments are usually computed directly by plugging in the coordinates into spherical harmonic equations. <span id="id18">[<a class="reference internal" href="#id118" title="Risi Kondor, Zhen Lin, and Shubhendu Trivedi. Clebsch-gordan nets: a fully fourier space spherical convolutional neural network. arXiv preprint arXiv:1806.09231, 2018.">KLT18</a>]</span> showed that this is itself nonlinear, and thus a complete layer with nonlinearity would be that equation combined with Equation <a class="reference internal" href="#equation-compact-gequiv">(10.17)</a>. We may also choose to skip some of the terms, since this is an exepnsive equation.</p>
<p>There is another kind of nonlinearity that is equivariant called gated nonlinearities <span id="id19">[<a class="reference internal" href="data.html#id65" title="Maurice Weiler, Mario Geiger, Max Welling, Wouter Boomsma, and Taco S Cohen. 3d steerable cnns: learning rotationally equivariant features in volumetric data. In Advances in Neural Information Processing Systems, 10381‚Äì10392. 2018.">WGW+18</a>]</span>. The equation is simple; just compute the magnitude of each of the irrep fragments <span class="math notranslate nohighlight">\(\vec{f}_i\)</span> and put it through a traditional neural network nonlinearity (e.g., ReLU):</p>
<div class="math notranslate nohighlight">
\[
\sigma_{\textrm{gated}}(\vec{f}_i) = \sigma\left(|\vec{f}_i|\right)\vec{f}_i
\]</div>
<p>The gated nonlinearity is sometimes used instead of Equation <a class="reference internal" href="#equation-cg-nl">(10.18)</a> or as an extra step after it <span id="id20">[<a class="reference internal" href="data.html#id64" title="Nathaniel Thomas, Tess Smidt, Steven Kearnes, Lusann Yang, Li Li, Kai Kohlhoff, and Patrick Riley. Tensor field networks: rotation-and translation-equivariant neural networks for 3d point clouds. arXiv preprint arXiv:1802.08219, 2018.">TSK+18</a>]</span>.</p>
<p>At the end of the network, most of the time we simply take the <span class="math notranslate nohighlight">\(f_0\)</span> scalar (the <span class="math notranslate nohighlight">\(l=0\)</span> irrep fragment). We may have multiple channels, so we don‚Äôt have one <span class="math notranslate nohighlight">\(f_0\)</span>. But, often we are doing classification or predicting energy (and its derivative, forces) and thus want a <span class="math notranslate nohighlight">\(l = 0\)</span> feature. The Clebsch-Gordan tensor products are essential to ensure mixing between the spatial information at the higher dimensional irrep fragments and scalar input features like atomic number.</p>
</section>
</section>
<section id="so-3-equivariant-example">
<h2><span class="section-number">10.11. </span>SO(3) Equivariant Example<a class="headerlink" href="#so-3-equivariant-example" title="Permalink to this headline">¬∂</a></h2>
<p>Let‚Äôs implement a non-differentiable version of the equations above for the SO(3) group. To begin, let‚Äôs write the code to convert our points into their irreps. Our code is not differentiable, so we won‚Äôt be able to train.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">sph_harm</span>


<span class="k">def</span> <span class="nf">cart2irreps</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">l</span><span class="p">):</span>
    <span class="c1"># convert to spherical coords to eval</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">azimuth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arctan2</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">polar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arccos</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">r</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">li</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">l</span><span class="p">):</span>
        <span class="n">fi</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">li</span><span class="p">,</span> <span class="n">li</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">sph_harm</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">li</span><span class="p">,</span> <span class="n">azimuth</span><span class="p">,</span> <span class="n">polar</span><span class="p">)</span>
            <span class="c1"># convert to real</span>
            <span class="k">if</span> <span class="n">m</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="n">m</span> <span class="o">*</span> <span class="n">y</span><span class="o">.</span><span class="n">imag</span>
            <span class="k">elif</span> <span class="n">m</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="n">m</span> <span class="o">*</span> <span class="n">y</span><span class="o">.</span><span class="n">real</span>
            <span class="n">fi</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">real</span><span class="p">)</span>
        <span class="n">fi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">fi</span><span class="p">)</span>
        <span class="n">f</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fi</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">li</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">f</span>


<span class="k">def</span> <span class="nf">print_irreps</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">f</span><span class="p">)):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;irrep </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">f</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> channels)&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;irrep </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> (no channels)&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>


<span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="c1"># make them be on unit sphere</span>
<span class="n">points</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of irreps</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">cart2irreps</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
<span class="n">print_irreps</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>irrep 0 (no channels)
[[0.28209479]
 [0.28209479]]
irrep 1 (no channels)
[[0.30938929 0.35978765 0.34151954]
 [0.25147992 0.16240408 0.21457659]]
irrep 2 (no channels)
[[-0.229949   -0.3533116   0.48355975  0.41407486  0.14687347]
 [-0.06474223  0.25382933  0.24695337 -0.15868095 -0.19084746]]
</pre></div>
</div>
</div>
</div>
<p>We chose to use 3 irreps here and get a fragment vector for each particle at each irrep. This gives a scalar for <span class="math notranslate nohighlight">\(l=0\)</span> irrep, a 3 dimensional vector for <span class="math notranslate nohighlight">\(l=1\)</span>, and a 5 dimensional vector for <span class="math notranslate nohighlight">\(l=2\)</span> irrep. It‚Äôs a choice, but usually you‚Äôll see networks encode a 3D point into the <span class="math notranslate nohighlight">\(l=1\)</span> irrep because it‚Äôs the smallest irrep that won‚Äôt become invariant. This also allows a sort of separation of input features, where we can put scalar properties like mass or element into the <span class="math notranslate nohighlight">\(l = 0\)</span> irrep and the point position into the <span class="math notranslate nohighlight">\(l=1\)</span> irrep. Often, you‚Äôll also see multiple channels (multiple sets of fragments at a given irrep) to add expressiveness.</p>
<p>Notice that <span class="math notranslate nohighlight">\(l=0\)</span> is the same for both points - that‚Äôs because the first spherical harmonic is constant. Another reason to put scalar quantities there!</p>
<p>Let‚Äôs now implement the linear part - Equation <a class="reference internal" href="#equation-compact-gequiv">(10.17)</a>. We‚Äôll have channels now, since otherwise we get a single weight.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">linear</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">W</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">f</span><span class="p">)):</span>
        <span class="c1"># promote to have channels, if not yet</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">f</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">f</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ijk,kl-&gt;ijl&quot;</span><span class="p">,</span> <span class="n">f</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">W</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">f</span>


<span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">cin</span><span class="p">,</span> <span class="n">cout</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">cin</span><span class="p">,</span> <span class="n">cout</span><span class="p">)</span>


<span class="n">weights</span> <span class="o">=</span> <span class="n">init_weights</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Input  shapes&quot;</span><span class="p">,</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">)]))</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">linear</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output shapes&quot;</span><span class="p">,</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">h</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">)]))</span>
<span class="n">print_irreps</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Input  shapes (2, 1),(2, 3),(2, 5)
Output shapes (2, 1, 4),(2, 3, 4),(2, 5, 4)
irrep 0 (4 channels)
[[[-0.31297784 -0.154452    0.18786586 -0.71498461]]

 [[-0.31297784 -0.154452    0.18786586 -0.71498461]]]
irrep 1 (4 channels)
[[[-0.42546735  0.15500163 -0.14858391  0.28962165]
  [-0.49477439  0.18025082 -0.17278767  0.33679993]
  [-0.46965237  0.17109864 -0.16401443  0.31969902]]

 [[-0.34583128  0.12598949 -0.12077299  0.23541225]
  [-0.22333557  0.08136318 -0.0779944   0.15202768]
  [-0.2950824   0.10750121 -0.1030502   0.20086677]]]
irrep 2 (4 channels)
[[[-0.1860702   0.27550026 -0.09351039 -0.27632922]
  [-0.28589279  0.42330012 -0.14367667 -0.4245738 ]
  [ 0.39128702 -0.57934949  0.196643    0.58109271]
  [ 0.33506122 -0.49610014  0.16838648  0.49759287]
  [ 0.11884712 -0.17596806  0.05972714  0.17649754]]

 [[-0.05238814  0.0775672  -0.02632789 -0.0778006 ]
  [ 0.20539369 -0.30411111  0.10322149  0.30502616]
  [ 0.1998298  -0.29587308  0.10042534  0.29676334]
  [-0.1284015   0.19011452 -0.06452873 -0.19068656]
  [-0.15443     0.22865298 -0.07760947 -0.22934098]]]
</pre></div>
</div>
</div>
</div>
<p>You can see that we now have multiple channels at each irrep.</p>
<p>Now we‚Äôll implement the Clebsch-Gordan nonlinearity, Equation <a class="reference internal" href="#equation-cg-nl">(10.18)</a>. We‚Äôll use the coefficients in sympy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sympy.physics.quantum.cg</span> <span class="kn">import</span> <span class="n">CG</span>
<span class="kn">from</span> <span class="nn">sympy</span> <span class="kn">import</span> <span class="n">S</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">lru_cache</span>


<span class="c1"># to speed-up repeated calls, put a cache around it</span>
<span class="nd">@lru_cache</span>
<span class="k">def</span> <span class="nf">cg</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="c1"># to get a float, we wrap input in symbol (S), call</span>
    <span class="c1"># doit, and evalf.</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">CG</span><span class="p">(</span><span class="n">S</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">S</span><span class="p">(</span><span class="n">j</span><span class="p">),</span> <span class="n">S</span><span class="p">(</span><span class="n">k</span><span class="p">),</span> <span class="n">S</span><span class="p">(</span><span class="n">l</span><span class="p">),</span> <span class="n">S</span><span class="p">(</span><span class="n">m</span><span class="p">),</span> <span class="n">S</span><span class="p">(</span><span class="n">n</span><span class="p">))</span><span class="o">.</span><span class="n">doit</span><span class="p">()</span><span class="o">.</span><span class="n">evalf</span><span class="p">()</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>


<span class="c1"># As you can see, the Clebsch-Gordan nonlinearity is a lot!!</span>
<span class="k">def</span> <span class="nf">cgnl</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">fi</span><span class="p">)</span> <span class="k">for</span> <span class="n">fi</span> <span class="ow">in</span> <span class="n">f</span><span class="p">]</span>
    <span class="c1"># m,n -&gt; outputs</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">f</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">f</span><span class="p">)):</span>
                <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">k</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">f</span><span class="p">)):</span>
                        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">m</span><span class="p">,</span> <span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                            <span class="n">output</span><span class="p">[</span><span class="n">m</span><span class="p">][:,</span> <span class="n">n</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span>
                                <span class="n">f</span><span class="p">[</span><span class="n">i</span><span class="p">][:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">f</span><span class="p">[</span><span class="n">k</span><span class="p">][:,</span> <span class="n">l</span><span class="p">]</span> <span class="o">*</span> <span class="n">cg</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
                            <span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span>


<span class="n">print_irreps</span><span class="p">(</span><span class="n">cgnl</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>irrep 0 (4 channels)
[[[0.42489967 0.4032353  0.0964734  0.94690111]]

 [[0.11165005 0.03936491 0.03783205 0.52913038]]]
irrep 1 (4 channels)
[[[ 0.24885549 -0.05730307 -0.05889344 -0.39649116]
  [-0.05000888 -0.24971277 -0.12805358 -0.11797142]
  [ 0.14781777 -0.13169458 -0.08727785 -0.30940054]]

 [[ 0.16494686 -0.06671324 -0.05442168 -0.28454164]
  [ 0.13365903 -0.0284449  -0.03038242 -0.21118876]
  [ 0.18040701 -0.0355278  -0.03947416 -0.28288486]]]
irrep 2 (4 channels)
[[[ 0.55749603  0.18656926  0.03216769  0.77978823]
  [ 0.50911544 -0.02010282 -0.00947985  0.81664941]
  [-0.13146835 -0.07648033  0.07056881 -1.00717992]
  [-0.06505638  0.01613839  0.07100045 -0.77672149]
  [ 0.09459735 -0.15717732  0.02821465 -0.37198278]]

 [[ 0.1384026  -0.10437677 -0.00300055  0.08031154]
  [-0.05399183  0.03246938  0.04335287 -0.46199106]
  [-0.11401494  0.01293701  0.03401445 -0.48684213]
  [ 0.15902584 -0.06563252 -0.01575307  0.29445021]
  [ 0.2021304  -0.13665679 -0.02137265  0.30913128]]]
</pre></div>
</div>
</div>
</div>
<p>Now we can make our complete layer! We won‚Äôt use a gated nonlinearity here, just the Clebsch-Gordan nonlinearity.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">cg_net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">cart2irreps</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">linear</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">W</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">cgnl</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>


<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">L</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">channels</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">weights</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">[</span><span class="n">init_weights</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">channels</span><span class="p">)]</span>
    <span class="o">+</span> <span class="p">[</span><span class="n">init_weights</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)]</span>
    <span class="o">+</span> <span class="p">[</span><span class="n">init_weights</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">)</span>

<span class="n">cg_net</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([5.71056675e+01, 2.06055946e-02])
</pre></div>
</div>
</div>
</div>
<p>Now we have our irrep features. How do we get an output? If we‚Äôre trying to output a scalar (regression/classification), we would just take the <span class="math notranslate nohighlight">\(l = 0\)</span> irrep fragment. Remember that we have a function with irreps (Equation <a class="reference internal" href="#equation-fft">(10.15)</a>), so getting out a point from a function can be done a few ways. One example is to read out the point at which the function (the product of fragments and spherical harmonics) is maximized. Or you could compute its average via integration.</p>
<p>Let us now check that our network is indeed invariant (we‚Äôre outputting a single value per point, so invariant). We‚Äôll make a rotation and check if our output changes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># random 3x3 matrix</span>
<span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="c1"># make it a member of SO(3)</span>
<span class="n">U</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
<span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">cg_net</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cg_net</span><span class="p">(</span><span class="n">points</span> <span class="o">@</span> <span class="n">R</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[5.71056675e+01 2.06055946e-02]
[4.52543928 0.30593967]
</pre></div>
</div>
</div>
</div>
<p><em>As you can see, something is broken and I need to fix it when I have time.</em></p>
</section>
<section id="equivariant-neural-networks-with-constraints">
<h2><span class="section-number">10.12. </span>Equivariant Neural Networks with Constraints<a class="headerlink" href="#equivariant-neural-networks-with-constraints" title="Permalink to this headline">¬∂</a></h2>
<p>You do not need to use irreducible representations. It is currently in 2022 the dominant paradigm due to its good accuracy. One alternative is to work in the defining/faithful representation and put equivariant constraints on your network weights. This approach is quite nice because the implementation is independent of the group. It also works for finite groups. Let‚Äôs see an example of this approach via the library released by the authors called Equivariant MLP (<code class="docutils literal notranslate"><span class="pre">emlp</span></code>)<span id="id21">[<a class="reference internal" href="#id149" title="Marc Finzi, Max Welling, and Andrew Gordon Wilson. A practical method for constructing equivariant multilayer perceptrons for arbitrary matrix groups. Arxiv, 2021.">FWW21</a>]</span></p>
<p>We‚Äôll create an SO(3) equivariant neural network and check that it is equivariant to rotations. We begin by defining our group and its representation. I‚Äôll show a few elements too, to demonstrate that this is the faithful representation and not the irreducible.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">emlp.groups</span> <span class="kn">import</span> <span class="n">SO</span><span class="p">,</span> <span class="n">S</span>
<span class="kn">import</span> <span class="nn">emlp.reps</span> <span class="k">as</span> <span class="nn">reps</span>
<span class="kn">import</span> <span class="nn">emlp</span>
<span class="kn">import</span> <span class="nn">haiku</span> <span class="k">as</span> <span class="nn">hk</span>
<span class="kn">import</span> <span class="nn">emlp.nn.haiku</span> <span class="k">as</span> <span class="nn">ehk</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>

<span class="n">so3_rep</span> <span class="o">=</span> <span class="n">reps</span><span class="o">.</span><span class="n">V</span><span class="p">(</span><span class="n">SO</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
<span class="c1"># grab a random group element</span>
<span class="n">sampled_g</span> <span class="o">=</span> <span class="n">SO</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="n">dense_rep</span> <span class="o">=</span> <span class="n">so3_rep</span><span class="o">.</span><span class="n">rho</span><span class="p">(</span><span class="n">sampled_g</span><span class="p">)</span>
<span class="c1"># check its a member of SO(3)</span>
<span class="c1"># g @ g.T = I</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dense_rep</span> <span class="o">@</span> <span class="n">dense_rep</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 1.0000001e+00 -9.0145235e-08 -3.6942627e-08]
 [-9.0145235e-08  1.0000000e+00  3.4498189e-08]
 [-3.6942627e-08  3.4498189e-08  9.9999994e-01]]
</pre></div>
</div>
</div>
</div>
<p>Now we‚Äôll apply our group element to a point to see it rotate the point. The norm should be unchanged, because it‚Äôs a rotation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">point</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;new point&quot;</span><span class="p">,</span> <span class="n">dense_rep</span> <span class="o">@</span> <span class="n">point</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;norm&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">dense_rep</span> <span class="o">@</span> <span class="n">point</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>new point [ 0.2110719  -0.73052925 -0.6494426 ]
norm 1.0
</pre></div>
</div>
</div>
</div>
<p>Now let‚Äôs assume our input function consists of 5 points (e.g., methanol molecule) defined by features (e.g., 1D element embedding) and positions. We‚Äôll create that as a direct sum of 5 scalars and 5 vectors. Our output will be a vector (e.g., dipole). Equivariance here will then mean that if rotate the input points, our output vector should undergo the same rotation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_rep</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">so3_rep</span><span class="o">**</span><span class="mi">0</span> <span class="o">+</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">so3_rep</span><span class="o">**</span><span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;input rep&quot;</span><span class="p">,</span> <span class="n">input_rep</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output rep&quot;</span><span class="p">,</span> <span class="n">so3_rep</span><span class="p">)</span>

<span class="n">input_point</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span> <span class="o">+</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;input features&quot;</span><span class="p">,</span> <span class="n">input_point</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;input positions</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">input_point</span><span class="p">[</span><span class="mi">5</span><span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>input rep 5V‚Å∞+5V
output rep V
input features [-0.30458234 -1.89067604  0.97765169 -0.18302214  0.59400493]
input positions
 [[ 0.54096229 -0.44211156 -0.5074754 ]
 [-0.71190593  1.1881366  -1.81726978]
 [-1.48572616 -0.69015372  3.02716867]
 [-1.24053084  0.07303629  0.19194001]
 [ 0.59835643 -0.70481736  1.01966388]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">emlp</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">EMLP</span><span class="p">(</span><span class="n">input_rep</span><span class="p">,</span> <span class="n">so3_rep</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="n">SO</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">output_point</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_point</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">,</span> <span class="n">output_point</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>output [ 0.00287231  0.00271389 -0.02050202]
</pre></div>
</div>
</div>
</div>
<p>Now we‚Äôll transform the input points according to a random element in the group. We could convert the input into the five spatial vectors and apply the group element to them individually and put them back together. However, <code class="docutils literal notranslate"><span class="pre">emlp</span></code> has a convenience function for exactly that. We can change our group element to the input representation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trans_input_point</span> <span class="o">=</span> <span class="n">input_rep</span><span class="o">.</span><span class="n">rho_dense</span><span class="p">(</span><span class="n">sampled_g</span><span class="p">)</span> <span class="o">@</span> <span class="n">input_point</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;transformed input features&quot;</span><span class="p">,</span> <span class="n">trans_input_point</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;transformed input positions</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">trans_input_point</span><span class="p">[</span><span class="mi">5</span><span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>transformed input features [-0.30458233 -1.890676    0.9776517  -0.18302214  0.5940049 ]
transformed input positions
 [[ 0.5648738   0.3965097   0.5189717 ]
 [-1.7186793   0.9593498   1.1604906 ]
 [ 0.20919645 -1.2322842  -3.207048  ]
 [-0.8010346   0.31936038 -0.91512   ]
 [ 1.1189423  -0.5973959  -0.5344146 ]]
</pre></div>
</div>
</div>
</div>
<p>Now we compare running the transformed input through the model against applying the group element to the output from the untransformed input.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">(</span><span class="n">trans_input_point</span><span class="p">),</span> <span class="n">sampled_g</span> <span class="o">@</span> <span class="n">output_point</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(DeviceArray([-0.00452228,  0.01232373,  0.01623647], dtype=float32),
 DeviceArray([-0.00452227,  0.01232371,  0.01623648], dtype=float32))
</pre></div>
</div>
</div>
</div>
<p>Indeed they are equivalent ‚Äì meaning this model is equivariant. The constraint approach is quite simple to use and can handle arbitrary groups. However, it may not be efficient when working with many input points (like a protein) and it may make sense to use an implementation specific to E(3) or SO(3).</p>
<section id="how-the-constraints-work">
<h3><span class="section-number">10.12.1. </span>How the constraints work<a class="headerlink" href="#how-the-constraints-work" title="Permalink to this headline">¬∂</a></h3>
<p>How does this magic happen? Rather than explicitly setting constraints on the dense layer weights, <code class="docutils literal notranslate"><span class="pre">emlp</span></code> always first projects the network weights into an <strong>equivariant subspace.</strong> This means that the cost of equivariance is paid when constructing the model when this projection matrix is found but not later during training and inference. The equivariant subspace is the space of allowed weights that respect the equivariance. Let‚Äôs see what this looks like.</p>
<p>Recall that a dense layer has the equation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-423c94cf-c126-4d6d-9664-a310a1564202">
<span class="eqno">(10.19)<a class="headerlink" href="#equation-423c94cf-c126-4d6d-9664-a310a1564202" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}
y = \sigma\left(Wx + b\right)
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma\)</span> is a special nonlinearity for equivariant neural networks we won‚Äôt discuss here (see <span id="id22">[<a class="reference internal" href="data.html#id65" title="Maurice Weiler, Mario Geiger, Max Welling, Wouter Boomsma, and Taco S Cohen. 3d steerable cnns: learning rotationally equivariant features in volumetric data. In Advances in Neural Information Processing Systems, 10381‚Äì10392. 2018.">WGW+18</a>]</span>). To respect the equivariance, <span class="math notranslate nohighlight">\(W,b\)</span> will need to be projected into an equivariant subspace that depends on our group and input/output representations. So our modified equation would look like:</p>
<div class="amsmath math notranslate nohighlight" id="equation-356659f0-86b5-4071-9539-20c5f719895c">
<span class="eqno">(10.20)<a class="headerlink" href="#equation-356659f0-86b5-4071-9539-20c5f719895c" title="Permalink to this equation">¬∂</a></span>\[\begin{equation}
y = \sigma\left(P_wWx + P_bb\right)
\end{equation}\]</div>
<p>Let‚Äôs start by making these projectors. <span class="math notranslate nohighlight">\(P_b\)</span> only will need to consider the output rep, since <span class="math notranslate nohighlight">\(b\)</span> is the bias (same representation as output).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pw</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_rep</span> <span class="o">&gt;&gt;</span> <span class="n">so3_rep</span><span class="p">)</span><span class="o">.</span><span class="n">equivariant_projector</span><span class="p">()</span>
<span class="n">Pb</span> <span class="o">=</span> <span class="p">(</span><span class="n">so3_rep</span><span class="p">)</span><span class="o">.</span><span class="n">equivariant_projector</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pw shape is&quot;</span><span class="p">,</span> <span class="n">Pw</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;Pb shape is&quot;</span><span class="p">,</span> <span class="n">Pb</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pw shape is (60, 60) Pb shape is (3, 3)
</pre></div>
</div>
</div>
</div>
<p>Note that they are square because they should leave the underlying dimension of <span class="math notranslate nohighlight">\(W\)</span> unchanged ‚Äì we are not projecting to a reduce dimension, but a subspace within the space of possible values of the weights. Remember too our representations are flattened - that 60 comes from the fact that our weight matrix is <span class="math notranslate nohighlight">\(3\times(5 + 15)\)</span>.</p>
<p>Now let‚Äôs show how these projectors can convert an arbitrary weight matrix into one that is equivariant.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span> <span class="o">+</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;W is not alone equivariant&quot;</span><span class="p">,</span>
    <span class="n">W</span> <span class="o">@</span> <span class="n">trans_input_point</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
    <span class="s2">&quot;!=&quot;</span><span class="p">,</span>
    <span class="n">sampled_g</span> <span class="o">@</span> <span class="n">W</span> <span class="o">@</span> <span class="n">input_point</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>W is not alone equivariant [ -3.1314962 -12.084191   11.542714 ] != [12.0744295 -2.836445   3.0263994]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Proj_W</span> <span class="o">=</span> <span class="p">(</span><span class="n">Pw</span> <span class="o">@</span> <span class="n">W</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Projected W is equivariant&quot;</span><span class="p">,</span>
    <span class="n">Proj_W</span> <span class="o">@</span> <span class="n">trans_input_point</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
    <span class="s2">&quot;==&quot;</span><span class="p">,</span>
    <span class="n">sampled_g</span> <span class="o">@</span> <span class="n">Proj_W</span> <span class="o">@</span> <span class="n">input_point</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Projected W is equivariant [-1.0771617  1.4464631  1.6674505] == [-1.0771616  1.4464632  1.6674507]
</pre></div>
</div>
</div>
</div>
<p>You may be wondering how much the projection affects <span class="math notranslate nohighlight">\(W\)</span>. Is there enough flexibility that you can learn? We can compare the full <em>random</em> matrix <span class="math notranslate nohighlight">\(W\)</span> vs it‚Äôs projection.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Random W&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Projected W&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">Proj_W</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Equivariant_78_0.png" src="../_images/Equivariant_78_0.png" />
<img alt="../_images/Equivariant_78_1.png" src="../_images/Equivariant_78_1.png" />
</div>
</div>
<p>It appears that there are only a few unique values in <span class="math notranslate nohighlight">\(W\)</span> after projection, so that our weight space is effectively much lower dimensional. This is why it‚Äôs important to have multiple channels! This also demonstrates why <code class="docutils literal notranslate"><span class="pre">emlp</span></code> can be more expensive. We‚Äôre training 180 values but we could have just used a few. Similarly, the projected bias is zero for our system.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pb</span> <span class="o">@</span> <span class="n">b</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DeviceArray([0., 0., 0.], dtype=float32)
</pre></div>
</div>
</div>
</div>
</section>
<section id="including-permutation-groups">
<h3><span class="section-number">10.12.2. </span>Including Permutation Groups<a class="headerlink" href="#including-permutation-groups" title="Permalink to this headline">¬∂</a></h3>
<p>In real molecules, we also need to have permutation equivariance with respect to the atom ordering and bond ordering ‚Äì which is not true of our above example about computing dipole moment. <code class="docutils literal notranslate"><span class="pre">emlp</span></code> also supports permutation groups, which are usually written as <span class="math notranslate nohighlight">\(S_n\)</span>, where <span class="math notranslate nohighlight">\(n\)</span> is the number of permutable elements in the group. We‚Äôll work on that in the next chapter.</p>
</section>
</section>
<section id="chapter-summary">
<h2><span class="section-number">10.13. </span>Chapter Summary<a class="headerlink" href="#chapter-summary" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p>Equivariant neural networks guarantee equivariance by construction for arbitrary groups, which removes the need to align trajectories, work in special coordinate systems, or use pairwise distances.</p></li>
<li><p>Equivariance can be achieved by parameter sharing or testing/training data augmentation, but here we focused on equivariant layers that can be composed into a neural network.</p></li>
<li><p>Equivariance requires definition of a group and homogeneous space. We must view our input data as functions and our models as operators that transform functions.</p></li>
<li><p>Finite groups can be treated with G-equivariant layers that have an additional sum across the number of group elements.</p></li>
<li><p>Infinite groups like SO(3) can be made finite by working with a direct sum (list of vectors) of the irreducible representations. This requires converting the input data though to the irreducible representation and there are complexities in nonlinearities and implementations typically must be written per-group.</p></li>
<li><p>Constraint-based equivariant layers are flexible, general, and quick to implement but may not scale well with respect to size of input group or number of points.</p></li>
<li><p>Recent work has also shown you can put irreducible representation direct sums into the edges of graph neural networks, gaining input size independence, permutation invariance, and spatial equivariance in one model.</p></li>
</ul>
</section>
<section id="relevant-videos">
<h2><span class="section-number">10.14. </span>Relevant Videos<a class="headerlink" href="#relevant-videos" title="Permalink to this headline">¬∂</a></h2>
<section id="intro-to-geometric-deep-learning">
<h3><span class="section-number">10.14.1. </span>Intro to Geometric Deep Learning<a class="headerlink" href="#intro-to-geometric-deep-learning" title="Permalink to this headline">¬∂</a></h3>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/w6Pw4MOzMuo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</section>
<section id="equivariant-networks">
<h3><span class="section-number">10.14.2. </span>Equivariant Networks<a class="headerlink" href="#equivariant-networks" title="Permalink to this headline">¬∂</a></h3>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/VN2biLjqJXc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</section>
<section id="equivariant-network-tutorial">
<h3><span class="section-number">10.14.3. </span>Equivariant Network Tutorial<a class="headerlink" href="#equivariant-network-tutorial" title="Permalink to this headline">¬∂</a></h3>
<p><a class="reference external" href="https://slideslive.com/38943570/equivariant-networks">watch here</a></p>
</section>
</section>
<section id="cited-references">
<h2><span class="section-number">10.15. </span>Cited References<a class="headerlink" href="#cited-references" title="Permalink to this headline">¬∂</a></h2>
<div class="docutils container" id="id23">
<dl class="citation">
<dt class="label" id="id71"><span class="brackets"><a class="fn-backref" href="#id20">TSK+18</a></span></dt>
<dd><p>Nathaniel Thomas, Tess Smidt, Steven Kearnes, Lusann Yang, Li¬†Li, Kai Kohlhoff, and Patrick Riley. Tensor field networks: rotation-and translation-equivariant neural networks for 3d point clouds. <em>arXiv preprint arXiv:1802.08219</em>, 2018.</p>
</dd>
<dt class="label" id="id72"><span class="brackets">WGW+18</span><span class="fn-backref">(<a href="#id19">1</a>,<a href="#id22">2</a>)</span></dt>
<dd><p>Maurice Weiler, Mario Geiger, Max Welling, Wouter Boomsma, and Taco¬†S Cohen. 3d steerable cnns: learning rotationally equivariant features in volumetric data. In <em>Advances in Neural Information Processing Systems</em>, 10381‚Äì10392. 2018.</p>
</dd>
<dt class="label" id="id107"><span class="brackets">FSIW20</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id9">2</a>)</span></dt>
<dd><p>Marc Finzi, Samuel Stanton, Pavel Izmailov, and Andrew¬†Gordon Wilson. Generalizing convolutional neural networks for equivariance to lie groups on arbitrary continuous data. <em>arXiv preprint arXiv:2002.12880</em>, 2020.</p>
</dd>
<dt class="label" id="id105"><span class="brackets"><a class="fn-backref" href="#id1">CGW19</a></span></dt>
<dd><p>Taco¬†S Cohen, Mario Geiger, and Maurice Weiler. A general theory of equivariant cnns on homogeneous spaces. <em>Advances in neural information processing systems</em>, 32:9145‚Äì9156, 2019.</p>
</dd>
<dt class="label" id="id104"><span class="brackets">KT18</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id8">2</a>,<a href="#id13">3</a>,<a href="#id17">4</a>)</span></dt>
<dd><p>Risi Kondor and Shubhendu Trivedi. On the generalization of equivariance and convolution in neural networks to the action of compact groups. In <em>International Conference on Machine Learning</em>, 2747‚Äì2755. 2018.</p>
</dd>
<dt class="label" id="id117"><span class="brackets"><a class="fn-backref" href="#id1">LW20</a></span></dt>
<dd><p>Leon Lang and Maurice Weiler. A wigner-eckart theorem for group equivariant convolution kernels. <em>arXiv preprint arXiv:2010.10952</em>, 2020.</p>
</dd>
<dt class="label" id="id149"><span class="brackets">FWW21</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id21">2</a>)</span></dt>
<dd><p>Marc Finzi, Max Welling, and Andrew¬†Gordon Wilson. A practical method for constructing equivariant multilayer perceptrons for arbitrary matrix groups. <em>Arxiv</em>, 2021.</p>
</dd>
<dt class="label" id="id110"><span class="brackets"><a class="fn-backref" href="#id2">WAR20</a></span></dt>
<dd><p>Renhao Wang, Marjan Albooyeh, and Siamak Ravanbakhsh. Equivariant maps for hierarchical structures. <em>arXiv preprint arXiv:2006.03627</em>, 2020.</p>
</dd>
<dt class="label" id="id111"><span class="brackets"><a class="fn-backref" href="#id3">BSS+21</a></span></dt>
<dd><p>Simon Batzner, Tess¬†E. Smidt, Lixin Sun, Jonathan¬†P. Mailoa, Mordechai Kornbluth, Nicola Molinari, and Boris Kozinsky. Se(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials. <em>arXiv preprint arXiv:2101.03164</em>, 2021.</p>
</dd>
<dt class="label" id="id112"><span class="brackets"><a class="fn-backref" href="#id4">KGrossGunnemann20</a></span></dt>
<dd><p>Johannes Klicpera, Janek Gro√ü, and Stephan G√ºnnemann. Directional message passing for molecular graphs. <em>arXiv preprint arXiv:2003.03123</em>, 2020.</p>
</dd>
<dt class="label" id="id161"><span class="brackets"><a class="fn-backref" href="#id5">SHF+21</a></span></dt>
<dd><p>Victor¬†Garcia Satorras, Emiel Hoogeboom, Fabian¬†B. Fuchs, Ingmar Posner, and Max Welling. E(n) equivariant normalizing flows for molecule generation in 3d. <em>arXiv preprint arXiv:2105.09016</em>, 2021.</p>
</dd>
<dt class="label" id="id209"><span class="brackets"><a class="fn-backref" href="#id6">SK19</a></span></dt>
<dd><p>Connor Shorten and Taghi¬†M Khoshgoftaar. A survey on image data augmentation for deep learning. <em>Journal of big data</em>, 6(1):1‚Äì48, 2019.</p>
</dd>
<dt class="label" id="id114"><span class="brackets">Zee16</span><span class="fn-backref">(<a href="#id7">1</a>,<a href="#id15">2</a>)</span></dt>
<dd><p>Anthony Zee. <em>Group theory in a nutshell for physicists</em>. Princeton University Press, 2016.</p>
</dd>
<dt class="label" id="id108"><span class="brackets"><a class="fn-backref" href="#id10">RBTH20</a></span></dt>
<dd><p>David¬†W Romero, Erik¬†J Bekkers, Jakub¬†M Tomczak, and Mark Hoogendoorn. Attentive group equivariant convolutional networks. <em>arXiv</em>, pages arXiv‚Äì2002, 2020.</p>
</dd>
<dt class="label" id="id109"><span class="brackets">CW16</span><span class="fn-backref">(<a href="#id11">1</a>,<a href="#id12">2</a>)</span></dt>
<dd><p>Taco Cohen and Max Welling. Group equivariant convolutional networks. In <em>International conference on machine learning</em>, 2990‚Äì2999. 2016.</p>
</dd>
<dt class="label" id="id113"><span class="brackets">Ser77</span><span class="fn-backref">(<a href="#id14">1</a>,<a href="#id16">2</a>)</span></dt>
<dd><p>Jean-Pierre Serre. <em>Linear representations of finite groups</em>. Volume¬†42. Springer, 1977.</p>
</dd>
<dt class="label" id="id118"><span class="brackets"><a class="fn-backref" href="#id18">KLT18</a></span></dt>
<dd><p>Risi Kondor, Zhen Lin, and Shubhendu Trivedi. Clebsch-gordan nets: a fully fourier space spherical convolutional neural network. <em>arXiv preprint arXiv:1806.09231</em>, 2018.</p>
</dd>
</dl>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./dl"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="data.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">9. </span>Input Data &amp; Equivariances</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="molnets.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">11. </span>Modern Molecular NNs</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Andrew D. White<br/>
    
        &copy; Copyright 2022.<br/>
      <div class="extra_footer">
        <a href="http://thewhitelab.org">thewhitelab.org</a> <div id="wh-modal"> <button class="wh-venti-button" aria-label="close modal" id="wh-modal-close">‚úï</button> <img id="wh-modal-img"> </div>
      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>